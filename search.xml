<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[composition-model]]></title>
    <url>%2F2018%2F04%2F08%2Fcomposition-model%2F</url>
    <content type="text"><![CDATA[Composition in Distributional Models of SemanticsSemantic representationSemantic NetworksSemantic networks (Collins &amp; Quillian, 1969) represent concepts as nodes in a graph. Edges in the graph denote semantic relationships between concepts(e.g., DOG IS-A MAMMAL, DOG HAS TAIL) and word meaning is expressed by the number of type of connections to other words. In this framework, word similarity is a function of path length-semantically related words are expected to have shorter paths between them. Semantic networks constitute a somewhat idealized representation that abstracts away from real-word usage-they are traditionally hand coded by modelers who a priori decide which relationships are most relevant in representing meaning.More recent work (Steyvers &amp; Tenenbaum, 2005) creates a semantic network from word association norms (Nelson, McEvoy, &amp; Schreiber, 1999); however, these can only represent a small fraction of the vocabulary of an adult speaker. Feature-based ModelsFeature-based model has the idea that word meaning can be described in terms of feature lists (Smith &amp; Medin, 1981). Theories tend to differ with respect to their definition of features. In many cases, the features are obtained by asking native speakers to generate attributes they consider important in describing the meaning of a word. This allows the representation of each word by a distribution of numerical values over the feature set.Admittedly, norming studies have the potential of revealing which dimensions of meaning are psychologically salient. However, a number of difficulties arise when working with such data. For example, the number and types of attributes generated can vary substantially as a function of the amount of time devoted to each word. There are many degrees of freedom in the way that responses are coded and analyzed. And multiple subjects are required to create a representation for each word, which in practice limits elicitation studies to a small-size lexicon. Semantic Spaces]]></content>
      <tags>
        <tag>reading report</tag>
        <tag>natural language language</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Natural Language Processing Note]]></title>
    <url>%2F2018%2F03%2F31%2FNLP-note%2F</url>
    <content type="text"><![CDATA[Week OneIntroductionWhat is natural language processing?computers using natural language as input and/or outputNLP contains two types: understanding(NLU) and generation(NLG). ApplicationsMachine TranslationTranslate from one language to another.Information ExtractionTake some text as input, and produce structured(database) representation of some key content in the text.Goal: Map a document collection to structured databaseMotivation: Complex searches, Statistical queries. Text SummarizationTake a single document, or potentially a group of several documents, and try to condense them down to summarize main information in those documents. Dialogue SystemsHuman can interact with computer. Basic NLP ProblemsTaggingStrings to Tagged SequencesExamples:Part-of-speech taggingProfits(/N) soared(/V) at(/P) Boeing(/N) Co.(/N) .(/.) easily(/ADV) topping(/V) forecasts(/N) on (/P) Wall(/N) Street(/N) .(/.) Name Entity RecognitionProfits(/NA) soared(/NA) at(/NA) Boeing(/SC) Co.(/CC) .(/NA) easily(/NA) topping(/NA) forecasts(/NA) on (/NA) Wall(/SL) Street(/CL) .(/.)/NA: not any entity/SC: start of company/CC: continuation of company/SL: start of location/CL: continuation of location Parsing Challenges At last, a computer that understands you like your mother. AmbiguityThis sentence can be interpreted in different ways:1.It understands you as well as your mother understands you.2.It understands (that) you like your mother.3.It understands you as well as it understands your mother. Ambiguity at Many Levels:Acoustic levelIn speech recognition:1.”… a computer that understands you like your mother”2.”… a computer that understands lie cured mother” Syntactic level Semantic levelA word may have a variety of meanings and it may cause word sense ambiguity. Discourse (multi-clause) levelAlice says they’ve built a computer that understands you like your motherBut she… … doesn’t know any details … doesn’t understand me at allThis is an instance of anaphora, where she referees to some other discourse entity. Language Modeling· We have some (finite) vocabulary, say \mathcal{V}={\text{the, a, man, telescope, Beckham, two, ...}} · We have an (infinite) set of strings, \mathcal{V}^\dagger: the STOPa STOPthe fan STOPthe fan saw Beckham STOPthe fan saw saw STOPthe fan saw Beckham play for Real Madrid STOP · We have a training sample of example sentences in English· We need to “learn” a probability distribution p i.e., p is a function that satisfies \sum_{x\in\mathcal{V^\dagger}}p(x)=1,\ p(x)\ge0\text{ for all }x\in\mathcal{V^\dagger}Definition: A language model consists of a finite set \mathcal{V}, and a function p(x_1,x_2,...,x_n) such that:1.For any \in\mathcal{V^\dagger}, p(x_1,x_2,...,x_n)\ge 02.In addition, \sum_{\in\mathcal{V^\dagger}}p(x_1,x_2,...,x_n)=1 Language models are very useful in a broad range of applications, the most obvious perhaps being speech recognition and machine translation. In many applications it is very useful to have a good “prior” distribution p(x_1...x_n) over which sentences are or aren’t probable in a language. For example, in speech recognition the language model is combined with an acoustic model that models the pronunciation of different words: one way to think about it is that the acoustic model generates a large number of candidate sentences, together with probabilities; the language model is then used to reorder these possibilities based on how likely they are to be a sentence in the language.The techniques we describe for defining the function p, and for estimating the parameters of the resulting model from training examples, will be useful in several other contexts during the course: for example in hidden Markov models and in models for natural language parsing. A Naive MethodWe have N training sentences.For any sentence x_1...x_n,\ c(x_1...x_n) is the number of times the sentence is seen in our training data. p(x_1...x_n)=\frac{c(x_1...x_n)}{N}This is a poor model: in particular it will assign probability 0 to any sentence not seen in the training corpus. Thus it fails to generalize to sentences that have not seen in the training data. The key technical contribution of this chapter will be to introduce methods that do generalize to sentences that are not seen in our training data. Markov ModelsFirst-Order Markov Processes \begin{aligned}&P(X_1=x_1,X_2=x_2,...,X_n=x_n)\\=&P(X_1=x_1)\prod_{i=2}^nP(X_i=x_i|X_1=x_1,...,X_{i-1}=x_{i-1})\\=&P(X_1=x_1)\prod_{i=2}^nP(X_i=x_i|X_{i-1}=x_{i-1})\end{aligned}The first step is exact: by the chain rule of probabilities, any distribution P(X_1=x_1...X_n=x_n) can be written in this form. So we have made no assumptions in this step of the derivation. However, the second step is not necessarily exact: we have made the assumption that for any i\in\{2...n\}, for any x_1...x_i, P(X_i=x_i|X_1=x_1...X_{i-1}=x_{i-1})=P(X_i=x_i|X_{i-1}=x_{i-1})This is a first-order Markov assumption. We have assumed that the identity of the i’th word in the sequence depends only on the identity of the previous word, x_{i-1}. More formally, we have assumed that the value of X_i is conditionally independent of X_1...X_{i-2}, given the value of X_{i-1}. Second-Order Markov Processes \begin{aligned}&P(X_1=x_1,X_2=x_2,...,X_n=x_n)\\=&P(X_1=x_1) \times P(X_2=x_2|X_1=x_1)\prod_{i=3}^nP(X_i=x_i|X_{i-2}=x_{i-2},X_{i-1}=x_{i-1})\\=&\prod_{i=1}^nP(X_i=x_i|X_{i-2}=x_{i-2},X_{i-1}=x_{i-1})\end{aligned}(For convenience we assume x_0=x_{-1}=*, where * is a special “start” symbol.) Compared with first-order Markov process, we make a slightly weaker assumption, namely that each word depends on the previous two words in the sequence. And the second-order Markov process will form the basis of trigram language models. The length of sequence n can itself vary. We just assume that the n‘th word in the sequence, X_n is always equal to a special symbol, the STOP symbol. This symbol can only appear at the end of a sequence and it doesn’t belong to the set \mathcal{V}. Process: Initialize i = 1, and x_0=x_{-1}=* Generate x_i from the distribution P(X_i=x_i|X_{i-2}=x_{i-2},X_{i-1}=x_{i-1}) If x_i=STOP then return the sequence x_1...x_n. Otherwise, set i=i+1 and return to step 2. TrigramA trigram language model consists of a finite set \mathcal{V}, and a parameter q(w|u,v) for each trigram u,v,w such that w\in\mathcal{V}\cup\{STOP\}, and u,v\in\mathcal{V}\cup\{*\}. The value for q(w|u,v) can be interpreted as the probability of seeing the word w immediately after the bigram (u,v). For any sentence x_1...x_n where x_i\in\mathcal{V} for i = 1…(n-1), and x_n=STOP, the probability of the sentence under the trigram language model is p(x_1...x_n)=\prod_{i=1}^nq(x_i|x_{i-2},x_{i-1}), where we define x_0=x_{-1}=*. Estimation Problem:A natural estimate (the “maximum likelihood estimate”): q(w_i|w_{i-2},w_{i-1})=\frac{Count(w_{i-2},w_{i-1},w_i)}{Count(w_{i-2},w_{i-1})}For example: q(\text{barks|the, dog})=\frac{c(\text{the, dog, barks})}{c(\text{the, dog})}This way of estimating parameters runs into a very serious issue. Say our vocabulary size is N=|\mathcal{V}|, then there are N^3 parameters in the model. This leads to two problems:· Many of the above estimates will be q(w|u,v)=0, due to the count in the numerator being 0. This will lead to many trigram probabilities being systematically underestimated: it seems unreasonable to assign probability 0 to any trigram not seen in training data, given that the number of parameters of the model is typically very large in comparison to the number of words in the training corpus.· In cases where the denominator c(u,v) is equal to zero, the estimate is not well defined. PerplexityWe have some test data sentences x^{(1)},x^{(2)},...,x^{(m)}. Note that test sentences are “held out”, in the sense that they are not part of the corpus used to estimate the language model. (Just the same as normal machine learning problems.)We could look at the probability under our model \prod_{i=1}^mp(s_i).More conveniently, the log probability: \log\prod_{i=1}^mp(s_i)=\sum_{i=1}^m\log p(s_i)In fact the usual evaluation measure is : \text{Perplexity}=2^{-l}, \text{where }l=\frac{1}{M}\sum_{i=1}^m\log p(s_i)and M is the total number of words in the test data M=\sum_{i=1}^mn_i. n_i is the length of the i‘th test sentence. Linear Interpolationq_{ML}(w|u,v)=\frac{c(u,v,w)}{c(u,v)}q_{ML}(w|v)=\frac{c(v,w)}{c(v)}q_{ML}(w)=\frac{c(w)}{c()}The subscript ML means maximum-likelihood estimation. And c(w) is the number of times word w is seen in the training corpus, and c() is the total number of words seen in the training corpus.The trigram, bigram and unigram estimates have different strengths and weaknesses. The idea in linear interpolation is to use all three estimates, by taking a weighted average of the three estimates: q(w|u,v)=\lambda_1\times q_{ML}(w|u,v)+\lambda_2\times q_{ML}(w|v)+\lambda_3\times q_{ML}(w)Here \lambda_1, \lambda_2 and \lambda_3 are three additional parameters of the model, which satisfies lambda_1+\lambda_2+\lambda_3=1 and \lambda_i\ge0 for all i.(Our estimate correctly defines a distribution.) There are various ways of estimating the λ values. A common one is as follows. Say we have some additional held-out data(development data), which is separate from both our training and test corpora.Define c'(u,v,w) to be the number of times that the trigram (u,v,w) is seen in the development data. L(\lambda_1,\lambda_2,\lambda_3)=\sum_{u,v,w}c'(u,v,w)\log q(w|u,v)\\=\sum_{u,v,w}c'(u,v,w)\log(lambda_1\times q_{ML}(w|u,v)+\lambda_2\times q_{ML}(w|v)+\lambda_3\times q_{ML}(w))We would like to choose our λ values to maximize L(\lambda_1,\lambda_2,\lambda_3).(It means minimize perplexity.) The three parameters \lambda_1,\lambda_2,\lambda_3 can be interpreted as an indication of the confidence, or weight, placed on each of the trigram, bigram and unigram estimates. In practice, it is important to add an additional degree of freedom, by allowing the values for \lambda_1,\lambda_2,\lambda_3 to vary.Take a function \Pi that partitions historiese.g., \Pi(w_{i-2},w_{i-1})=\begin{cases}1\text{ If Count}(w_{i-1},w_{i-2})=0\\2\text{ If }1\le Count(w_{i-1},w_{i-2})\le2\\3\text{ If }3\le Count(w_{i-1},w_{i-2})\le5\\4\text{ Otherwise}\end{cases}Introduce a dependence of the λ’s on the partition: \begin{aligned}q(w_i|w_{i-2},w_{i-1})=&\lambda_1^{\Pi(w_{i-2},w_{i-1})}\times q_{ML}(w_i|w_{i-2},w_{i-1})\\ +&\lambda_2^{\Pi(w_{i-2},w_{i-1})}\times q_{ML}(w_i|w_{i-1})\\ +&\lambda_3^{\Pi(w_{i-2},w_{i-1})}\times q_{ML}(w_i)\end{aligned}where \lambda_1^{\Pi(w_{i-2},w_{i-1})}+\lambda_2^{\Pi(w_{i-2},w_{i-1})}+\lambda_3^{\Pi(w_{i-2},w_{i-1})}=1, and \lambda_i^{\Pi(w_{i-2},w_{i-1})}\ge0 for all i. By the way, lambda_1 should be 0 if c(u,v)=0, because in this case the trigram estimate q_{ML}(w|u,v)=\frac{c(u,v,w)}{c(u,v)} is undefined. Similarly, if both c(u,v) and c(v) are equal to zero, we need \lambda_1=\lambda_2=0 In the referencing note, a simple method is introduced: \lambda_1=\frac{c(u,v)}{c(u,v)+\gamma}\lambda_2=(1-\lambda_1)\times\frac{c(v)}{c(v)+\gamma}\lambda_3=1-\lambda_1-\lambda_2γ&gt;0.Under this definition, it can be seen that \lambda_1 increases as c(u,v) increases, and similarly that \lambda_2 increases as c(v) increases. This method is relatively crude, and is not likely to be optimal. It is, however, very simple, and in practice it can work well in some applications. Discounting MethodsFor any bigram Count(w_{i-1},w) such that Count(w_{i-1},w)>0, we define the discounted count as Count^*(w_{i-1},w)=Count(w_{i-1},w)-\betawhere β is a value between 0 and 1 (a typical value might be β=0.5). Thus we simply subtract a constant value, β, from the count. This reflects the intuition that if we take counts from the training corpus, we will systematically over-estimate the probability of bigrams seen in the corpus(and under-estimate bigrams not seen in the corpus).For any bigram (w_{i-1},w) such that Count(w_{i-1},w)>0, we can then define q(w|w_{i-1})=\frac{Count^*(w_{i-1},w)}{Count(w_{i-1})}. For any context w_{i-1}, this definition leads to some missing probability mass, defined as \alpha(v)=1-\sum_{w:Count(w_{i-1},w)>0}\frac{Count^*(w_{i-1},w)}{Count(w_{i-1})}The intuition behind discounted methods is to divide this “missing mass” between the words w such that Count(w_{i-1},w)=0.Define two sets \mathcal{A}(w_{i-1})=\{w:Count(w_{i-1},w)>0\mathcal{B}(w_{i-1})=\{w:Count(w_{i-1},w)=0Then the back-off model is defined as q_{BO}(w_i|w_{i-1})=\begin{cases}\frac{Count^*(w_{i-1},w_i)}{Count(w_{i-1})}\text{ if }w_i\in\mathcal{A}(w_{i-1})\\\alpha(w_{i-1})\frac{q_{ML}(w_i)}{\sum_{w\in\mathcal{B}(w_{i-1})}q_{ML}(w)}\text{ if }w_i\in\mathcal{B}(w_{i-1})\end{cases}Thus if Count(w_{i-1},w)>0 we return the estimate \frac{Count^*(w_{i-1},w_i)}{Count(w_{i-1})}; otherwise we divide the remaining probability mass \alpha(w_{i-1}) in proportion to the unigram estimate q_{ML}(w). The method can be generalized to trigram language models in a natural, recursive way: Week TwoTaggingGiven the input to the tagging model(referred as a sentence) x_1...x_n, use y_1...y_n to denote the output of the tagging model(referred as the state sequence or tag sequence).This type of problem, where the task is to map a sentence x_1...x_n to a tag sequence y_1...y_n is often referred to as a sequence labeling problem, or a tagging problem.We will assume that we have a set of training examples, (x^{(i)},y^{(i)}) for i=1...m, where each x^{(i)} is a sentence x_1^{(i)}...x_{n_i}^{(i)}, and each y^{(i)} is a tag sequence y^{(i)}_1...y^{(i)}_{n_i}(we assume that the i‘th training example is of length n_i). Hence x_j^{(i)} is the j‘th word in the i‘th training example, and y_j^{(i)} is the tag for that word. Our task is to learn a function that maps sentences to tag sequences from these training examples. POS TaggingPOS Tagging: Part-of-Speech tagging.The input to the problem is a sentence. The output is a tagged sentence, where each word in the sentence is annotated with its part of speech. Our goal will be to construct a model that recovers POS tags for sentences with high accuracy. POS tagging is one of the most basic problems in NLP, and is useful in many natural language applications. Tags D: determiner (a, an, the) N: noun V: verb P: preposition Adv: adverb Adj: adjective … ChallengesAmbiguityMany words in English can take several possible parts of speech(as well as in Chinese and many other languages). A word can be a noun as well as a verb. E.g., look, result…Rare wordsSome words are rare and may not be seen in the training examples. Even with say a million words of training data, there will be many words in new sentences which have not been seen in training. It will be important to develop methods that deal effectively with words which have not been seen in training data. Sources of informationLocalIndividual words have statistical preferences for their part of speech.E.g., can is more likely to be a modal verb rather than a noun. ContextualThe context has an important effect on the part of speech for a word. In particular, some sequences of POS tags are much more likely than others. If we consider POS trigrams, the sequence D N V will be frequent in English, whereas the sequence D V N is much less likely.Sometimes these two sources of evidence are in conflict. For example, in the sentence The trash can is hard to find, the part of speech for can is a noun-however, can can also be a modal verb, and in fact it is much more frequently seen as a modal verb in English. In this sentence the context has overridden the tendency for can to be a verb as opposed to a noun. Named-EntityFor named-entity problem, the input is again a sentence. The output is the sentence with entity-boundaries marked. Recognizing entities such as people, locations and organizations has many applications, and name-entity recognition has been widely studies in NLP research. Once this mapping has been performed on training examples, we can train a tagging model on these training examples. Given a new test sentence we can then recover the sequence of tags from the model, and it is straightforward to identify the entities identified by the model. Generative ModelsSupervised Learning:Assume training examples (x^{(1)},y^{(1)})...(x^{(m)},y^{(m)}), where each example consists of an input x^{(i)} paired with a label y^{(i)}. We use \mathcal{X} to refer to the set of possible inputs, and \mathcal{Y} to refer to the set of possible labels. Our task is to learn a function f:\mathcal{X}\to\mathcal{Y} that maps any input x to a label f(x).One way to define the function f(x) is through a conditional model. In this approach we define a model that defines the conditional probability p(y|x) for any x,y pair. The parameters of the model are estimated from the training examples. Given a new test example x, the output from the model is f(x)=\arg\max_{y\in\mathcal{Y}}p(y|x)Thus we simply take the most likely label y as the output from the model. If our model p(y|x) is close to the true conditional distribution of labels given inputs, the function f(x) will be close to optimal. Generative ModelsRather than directly estimating the conditional distribution p(y|x), in generative models we instead model the joint probability p(x,y) over (x,y) pairs. The parameters of the model p(x,y) are again estimated from the training examples (x^{(i)},y^{(i)}) for I=1...n. In many cases we further decompose the probability p(x,y) as p(x,y)=p(y)p(x|y) and then estimate the models for p(y) and p(x|y) separately. These two model components have the following interpretations:· p(y) is a prior probability distribution over labels y.· p(x|y) is the probability of generating the input x, given that the underlying label is y. Given a generative model, we can use Bayes rule to derive the condition probability p(y|x) for any (x,y) pair: p(y|x)=\frac{p(y)p(x|y)}{p(x)}where p(x)=\sum_{y\in\mathcal{Y}}p(x,y)=\sum_{y\in\mathcal{Y}}p(y)p(x|y)We use Bayes rule directly in applying the joint model to a new test example. Given an input x, the output of our model, f(x), can be derived as follows: \begin{aligned}f(x)&=\arg\max_yp(y|x)\\&=\arg\max_y\frac{p(y)p(x|y)}{p(x)}\text{ (2)}\\&=\arg\max_yp(y)p(x|y)\text{ (3)}\end{aligned}Eq. 2 follows by Bayes rule. Eq. 3 follows because the denominator, p(x), does not depend on y, and hence does not affect the arg max. This is convenient, because it mean that we do not need calculate p(x), which can be an expensive operation.Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that has been generated in two steps: first, a label y has been chosen with probability p(y); second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output. Our task is to find the most likely label y, given that we observe x. In summary: Our task is to learn a function from inputs x to labels y=f(x). We assume training examples (x^{(i)},y^{(i)}) for i=1...n. In the noisy channel approach, we use the training example to estimate models p(y) and p(x|y). These models define a joint(generative) model: p(x,y)=p(y)p(x|y) Given a new test example x, we predict the label f(x)=\arg\max_{y\in\mathcal{Y}}p(y)p(x|y). Finding the output f(x) for an input x is often referred to as the decoding problem.]]></content>
      <tags>
        <tag>natural language processing</tag>
        <tag>learning note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面向对象程序设计课堂笔记]]></title>
    <url>%2F2018%2F03%2F14%2Foop-note%2F</url>
    <content type="text"><![CDATA[Lecture 1序程序设计范型是指设计程序的规范、模型和风格，它是一类程序设计语言的基础。 面向过程程序设计范型：程序=过程+调用 或 程序=算法+数据结构 函数式程序设计范型：程序被看作“描述输入与输出之间关系”的数学函数。如LISP 面向对象程序设计是一种新型的程序设计范型。这种范型的主要特征是：对象=（算法+数据结构）程序=对象+消息 面向对象程序的主要结构特点：一、程序一般由类的定义和类的使用两部分组成，在主程序中定义各对象并规定它们之间传递消息的规律。二、程序中的一切操作都是通过向对象发送消息来实现的，对象接收到消息后，启动有关方法完成相应的操作。 基本概念 对象 Object 类 Class 消息 Message 方法 Method 对象在现实世界中，任何事物都是对象。可以使有形的具体存在的事物，也可以是无形的抽象的事件。对象一般可以表示为：属性+行为（单独的可以缺属性只定义行为，整个体系则缺一不可） 名字：用于区别不同的实体属性/状态：属性用于描述不同实体的特征状态由这个对象的属性和这些属性的当前值决定。操作：用于描述不同实体可具有的行为是对象提供给用户的一种服务，也叫行为或方法。· 对象的操作可以分为两类，一类是自身所承受的操作(private/protected)，一类是施加于其他对象的操作(public)。 方法(Method)——就是对象所能执行的操作，即服务。方法描述了对象执行操作的算法，响应消息的方法。在C++中称为成员函数。属性(Attribute)——就是类中所定义的数据，它是对客观世界实体所具有性质的抽象。C++中称为数据成员。 在面向对象程序设计中，对象是描述其属性的数据及对这些数据施加的一组操作封装在一起构成的统一体。对象可以认为是：数据+方法（操作） 类在现实世界中，类是一组具有相同属性和行为的对象的抽象。类和对象之间的关系式抽象和具体的关系。类是多个对象进行综合抽象的结果，一个对象是类的一个实例。在面向对象程序设计中，类就是具有相同数据和相同操作的一组对象的集合。是对具有相同数据结构和相同操作的一类对象的描述。在面向对象程序设计中，总是先声明类，再由类生成其对象。 注意不能把一组函数组合在一起构成类。即类不是函数的集合。 消息面向对象设计技术必须提供一种机制允许一个对象与另一个对象的交互，这种机制叫消息传递。在面向对象程序设计中，一个对象向另一个对象发出的请求被称为消息。当对象收到消息时，就调用有关的方法，执行相应的操作。消息是一个对象要求另一个对象执行某个操作的规格说明，通过消息传递才能完成对象之间的相互请求或相互协作。消息具有三个性质：(1).同一个对象可以接收不同形式的多个消息，作出不同的响应(2).相同形式的消息可以传递给不同的对象，所作出的响应可以是不同的。(3).对消息的响应并不是必需的，对象可以响应消息，也可以不响应。分为两类：公有消息（其他对象发出），私有消息（向自己发出）。 方法方法就是对象所能执行的操作。方法包括界面和方法体两部分。方法的界面就是消息的模式，它给出了方法调用的协议；方法体则是实现某种操作的一系列计算步骤，就是一段程序在C++语言中方法是通过函数来实现的，称为成员函数消息和方法的关系是：对象根据接收到的消息，调用相应的方法；反过来，有了方法，对象才能响应相应的消息。 面向对象程序设计的基本特征 抽象 Abstraction 封装 Encapsulation 继承 Inheritance 多态 Polymorphism 抽象抽象是通过特定的实例（对象）抽取共同性质以后形成概念的过程。抽象是对系统的简化描述和规范说明，他强调了系统中的一部分细节和特性，而忽略了其他部分。抽象包括两个方面，数据抽象和代码抽象（或称行为抽象）。前者描述某类对象的属性和状况，也就是此类对象区别于彼类对象的特征物理量；后者描述了某类对象的共同行为特征或具有的共同操作。在面向对象的程序设计方法中，对一个具体问题的抽象分析结果，是通过类来描述和实现的。 封装在面向对象程序设计中，封装是指把数据和实现操作的代码集中起来放在对象内部，并尽可能隐藏对象的内部细节。封装应该具有如下几个条件：（1）对象具有一个清晰的边界，对象的私有数据和实现操作的代码被封装在该边界内。（2）具有一个描述对象与其他对象如何相互作用的接口，该接口必须说明消息如何传递的使用方法。（3）对象内部的代码和数据应受到保护，其他对象不能直接修改。 继承继承是在一个已经建立的类的基础上再接着声明一个新类的扩展机制，原先已经建立的类称为基类，在基类之下扩展的类称为派生类，派生类又可以向下充当继续扩展的基类，因此构成层层派生的一个动态扩展过程。派生类享有基类的数据结构和算法，而本身又具有增加的行为和特性，因此继承的机制促进了程序代码的可重用性。一个基类可以有多个派生类，一个派生类反过来可以具有多个基类，形成复杂的继承树层次体系。 基类与派生类之间本质的关系：基类是一个简单的类，描述相对简单的事物，派生类是一个复杂些的类，处理相对复杂的现象。 继承的作用：避免公用代码的重复开发，减少代码和数据冗余。通过增强一致性来减少模块间的接口。继承分为单继承和多继承。 多态多态性是指不同的对象收到相同的消息时产生多种不同的行为方式。C++支持两种多态性：编译时的多态性（重载）和运行时的多态性（虚函数）。 为什么要使用OOP传统程序设计方法的局限性（1）传统程序设计开发软件的生产效率低下存在重用性、复杂性和可维护问题。(OOP三大优势)（2）传统程序设计难以应付日益庞大的信息量和多样的信息类型当代计算机所处理的数据已从最简单的数据和字符发展为多种格式的多媒体数据，如文本、图形、图像、影像、声音等。面对庞大的信息量和多样的信息格式，传统程序设计无法应付。（3）传统的程序设计难以适应各种新环境并行处理、分布式、网络和多机系统等节点之间的通信机制传统的程序设计技术很难处理。 OOP的主要优点（1）可提高程序的重用性（2）可控制程序的复杂性（3）可改善程序的可维护性（4）能够更好地支持大型程序设计（5）增强了计算机处理信息的范围（6）能很好地适应新的硬件环境 C++的优点C++继承了C的优点，并有自己的特点，主要有：（1）全面兼容C，C的许多代码不经修改就可以为C++所用，用C编写的库函数和实用软件可以用于C++。（2）用C++编写的程序可读性更好，代码结构更为合理，可直接在程序中映射问题空间结构。（3）生成代码的质量高，运行效率高。（4）从开发时间、费用到形成软件的可重用性、可扩充性、可维护性和可靠性等方面有了很大提高，使得大中型的程序开发项目变得容易得多。（5）支持面向对象的机制，可方便地构造出模拟现实问题的实体和操作。 C++对C的补充注释与续行注释符：/* */或//续行符：\。当一个语句太长时可以用该符号分段写在几行中note: 其实不加续航符直接换行也可以0.0E.g. 123456789#include&lt;iostream&gt;using namespace std;int main() &#123; cout &lt;&lt; "hello " &lt;&lt; "world" &lt;&lt; endl; return 0; This program will print hello world in a line. 输入输出流C: scanf和printfC++: cin&gt;&gt;和cout&lt;&lt;（用C的也可以，但是不推荐……）cout和cin分别是C++的标准输出流和输入流。C++支持重定向，但一般cout指的是屏幕，cin指的是键盘。操作符&lt;&lt;和&gt;&gt;除了具有C语言中定义的左移和右移的功能外，在这里符号&lt;&lt;是把右方的参数写到标准输出流cout中；相反，符号&gt;&gt;则是将标准输入流的数据赋给右方的变量。cin和&gt;&gt;，cout和&lt;&lt;配套使用使用cout和cin时，也可以对输入和输出的格式进行控制，比如可用不同的进制方式显示数据，只要设置转换基数的操作符dec、hex和oct即可。 灵活的变量说明定义变量的位置在程序中的不同位置采用不同的变量定义方式，决定了该变量具有不同的特点。变量的定义一般可由以下三种位置：（1）函数体内部在函数体内部定义的变量称为局部变量。（2）形式参数当定义一个有参函数时，函数名后面括号内的变量，统称为形式参数。（3）全局变量：在所有函数体外部定义的变量，其作用范围是整个程序，并在整个程序运行期间有效。 在C语言中，全局变量声明必须在任何函数之前，局部变量必须集中在可执行语句之前。C++中的变量声明非常灵活。它允许变量声明与可执行语句交替执行，随时声明。for (int i = 0; i &lt; 10; i++) 结构、联合和枚举名在C++中，结构名、联合名、枚举名都是类型名。在定义变量时，不必在结构名、联合名或枚举名前冠以struct、union或enum。如：定义枚举类型boole: enum boole{FALSE, TRUE};在C语言中定义变量需写成enum boole done;，但在C++中，可以说明为boole done;。 函数原型C语言建议编程者为程序中的每一个函数建立圆形，而C++要求为每一个函数建立原型，以说明函数的名称、参数类型与个数，以及函数返回值的类型。其主要目的是让C++编译程序进行类型检查，即形参与实参的类型匹配检查，以及返回值是否与原型相符，以维护程序的正确性。在程序中，要求一个函数的原型出现在该函数的调用语句之前。说明：（1）函数原型的参数表中可不包含参数的名字，而只包含它们的类型。例如long Area(int, int);（2）函数定义由函数首部和函数体构成。函数首部和函数原型基本一样，但函数首部中的参数必须给出名字而且不包含结尾的分号。（3）C++的参数说明必须放在函数说明后的括号内，不可将函数参数说明放在函数首部和函数体之间。这种方法只在C中成立。（4）主函数不必进行原型说明，因为它被看成自动说明原型的函数。（5）原型说明中没有指定返回类型的函数（包括主函数main），C++默认该函数的返回类型是int。（6）如果一个函数没有返回值，则必须在函数原型中注明返回类型为void，主函数类似处理。（7）如果函数原型中未注明参数，C++假定该函数的参数表为空(void)。 const修饰符C语言中习惯用#define定义常量，C++利用const定义正规常数一般格式 const 数据类型标识符 常数名 = 常量值采用这种方式定义的常量是类型化的，它有地址，可以用指针指向这个值，但不能修改它。const必须放在被修饰类型符和类型名前面。数据类型是可选项，用来指定常数值的数据类型，如果省略了数据类型，那么默认是int。const的作用于#define相似，但它消除了#define的不安全性。 const可以与指针一起使用。指向常量的指针、常指针和指向常量的常指针。1）指向常量的指针是指：一个指向常量的指针变量。2）常指针是指：把指针本身，而不是它指向的对象声明为常量。3）指向常量的常指针是指：这个指针本身不能改变，它所指向的值也不能改变。要声明一个指向常量的常指针，二者都要声明为const。 说明：（1）如果用const定义的是一个整型变量，关键词int可以省略。（2）常量一旦被建立，在程序的任何地方都不能再更改。（3）与#define定义的常量有所不同，const定义的常量可以有自己的数据类型，这样C++的编译程序可以进行更加严格的类型检查，具有良好的编译时的检测性。（4）函数参数也可以用const说明，用于保证实参在该函数内部不被改动。 void型指针void通常表示无值，但将void作为指针的类型时，它却表示不确定的类型。这种void型指针是一种通用型指针，也就是说任何类型的指针值都可以赋给void类型的指针变量。void型指针可以接受任何类型的指针的赋值，但对已获值的void型指针，对它在进行处理，如输出或传递指针值时，则必须进行强制类型转换，否则会出错。 1234567891011121314#include &lt;iostream&gt;using namespace std;int main() &#123; void *pc; int i = 456; char c = 'a'; pc = &amp;i; cout &lt;&lt; *(int *)pc &lt;&lt; endl; pc = &amp;c; cout &lt;&lt; *(char *)pc &lt;&lt; endl; return 0;&#125; 内联函数调用函数时系统要付出一定的开销，用于信息入栈出栈和参数传递等。C++引进了内联函数(inline function)的概念。在进行程序的编译时，编译器将内联函数的目标代码作拷贝并将其插入到调用内联函数的地方。12345678910111213#include &lt;iostream&gt;using namespace std;inline double circle(double r) &#123; return 3.1416 * r * r;&#125;int main() &#123; for (int i = 0; i &lt; 3; ++i) &#123; cout &lt;&lt; "r = " &lt;&lt; i &lt;&lt; " area = " &lt;&lt; circle(i) &lt;&lt; endl; &#125; return 0;&#125; 说明：（1）内联函数在第一次被调用前必须进行声明或定义。否则编译器无法知道应该插入什么代码（2）C++的内联函数具有与C中的宏定义#define相同的作用和类似机理，但消除了#define的不安全性。（3）内联函数体内一般不能有循环语句和开关语句。（4）后面类结构中所有在类说明体内定义的函数都是内联函数。（5）通常较短的函数才定义为内联函数。 带有缺省参数值的函数在C++中，函数的参数可以有缺省值。当调用有缺省参数的函数时，如果相应的参数没有给出实参，则自动用相应的缺省参数作为其实参。函数的缺省参数，是在函数原型中给定的。说明（1）在函数原型中，所有取缺省值的参数必须出现在不取缺省值的参数的右边。（2）在函数调用时，若某个参数省略，则其后的参数皆应省略而采用缺省值。 函数重载函数重载是指一个函数可以和同一作用域（命名空间）中的其他函数具有相同的名字，但这些同名函数的参数类型、参数个数不同。为什么要使用函数重载？对于具有同一功能的函数，如果只是由于参数类型不一样，则可以定义相同名称的函数。 调用步骤：（1）寻找一个严格的匹配，即：调用与实参的数据类型、个数完全相同的那个函数。（2）通过内部转换寻求一个匹配，即：通过（1）的方法没有找到相匹配的函数时，则由C++系统对实参的数据类型进行内部转换，转换完毕后，如果有匹配的函数存在，则执行该函数。（3）通过用户定义的转换寻求一个匹配，若能查出有唯一的一组转换，就调用那个函数。即：在函数调用处由程序员对实参进行强制类型转换，以此作为查找相匹配的函数的依据。 注意事项：重载函数不能只是函数的返回值不同，应至少在形参的个数、参数类型或参数顺序上有所不同。应使所有的重载函数的功能相同。如果让重载函数完成不同的功能，会破坏程序的可读性。 函数模板函数模板：建立一个通用函数，其函数类型和形参类型不具体指定，而是一个虚拟类型。应用情况：凡是函数体相同的函数都可以用这个模板来代替，不必定义多个函数，只需在模板中定义一次即可。在调用函数时系统会根据实参的类型来取代模板中的虚拟类型，从而实现了不同函数的功能。template&lt;typename T&gt;通用函数定义，template&lt;class T&gt;通用函数定义(class和typename可以通用) 123456template&lt;typename T&gt;T max(T a, T b)&#123; if (b &gt; a) return b; else return a;&#125; 与重载函数比较：用函数模板比函数重载更方便，程序更简洁。但应注意它只适用于：函数参数个数相同而类型不同，且函数体相同的情况。如果参数的个数不同，则不能用函数模板。 作用域标识符::通常情况下，如果有两个同名变量，一个是全局的，另一个是局部的，那么局部变量在其作用域内具有较高的优先权。在全局变量加上::，此时::var代表全局变量。 无名联合无名联合是C++中的一种特殊联合，可以声明一组无标记名共享同一段内存地址的数据项。如: union {int i; float j;}在此无名联合中，声明了变量i和f具有相同的存储地址。无名联合可通过使用其中数据项名字直接存取，例如可以直接使用上面的变量i或f。 强制类型转换C中数据类型转换的一般形式 (数据类型标识符) 表达式C++支持这样的格式，还提供了一种更为方便的函数调用方法，即将类型名作为函数名使用，是的类型转换的执行看起来好像调用了一个函数。形式为：数据类型标识符 (表达式)。 动态内存分配作为对C语言中malloc和free的替换，C++引进了new和delete操作符。它们的功能是实现内存的动态分配和释放。指针变量=new 数据类型;或指针变量=new 数据类型(初始值); 例如：int *a, *b;a = new int;b = new int(10); 释放由new操作动态分配的内存时，用delete操作。delete 指针变量;例如delete a;，delete b;。 优点：（1）new和delete操作自动计算需要分配和释放类型的长度。这不但省去了用sizeof计算长度的步骤，更主要的是避免了内存分配和释放时因长度出错带来的严重后果。（2）new操作自动返回需分配类型的指针，无需使用强制类型转换。（3）new操作能初始化所分配的类型变量。（4）new和delete都可以被重载，允许建立自定义的内存管理法。 说明：（1）用new分配的空间，使用结束后应该用delete显示的释放，否则这部分空间将不能回收而变成死空间。（2）使用new动态分配内存时，如果没有足够的内存满足分配要求，new将返回空指针（NULL）。因此通常要对内存的动态分配是否成功进行检查。（3）使用new可以为数组动态分配内存空间。这时需要在类型后面加上数组大小。指针变量 = new 类型名[下标表达式];使用new为多维数组分配空间时，必须提供所有维的大小。（4）释放动态分配的数组存储区时，可使用delete运算符 引用引用就是某一变量（目标）的一个别名，这样对引用的操作就是对目标的操作。引用的声明方法：类型标识符 &amp;引用名=目标变量名;说明：（1）&amp;在此不是求地址运算，而是起标识作用。（2）类型标识符是指目标变量的类型。（3）声明引用时，必须同时对其进行初始化。（4）引用声明完毕后，相当于目标变量名有两个名称。（5）声明一个引用，不是新定义了一个变量，系统并不给引用分配存储单元。 引用的使用（1）引用名可以是任何合法的变量名。除了用作函数的参数或返回类型外，在声明时，必须立即对它进行初始化，不能声明完后再赋值。（2）引用不能重新赋值，不能再把该引用名作为其他变量名的别名，任何对该引用的赋值就是该引用对应的目标变量名的赋值。对引用求地址，就是对目标变量求地址。（3）由于指针变量也是变量，所以，可以声明一个指针变量的引用。方法是类型标识符 *&amp;引用名=指针变量名（4）引用是对某一变量或目标对象的引用，它本身不是一种数据类型，因此引用本身不占存储单元，这样，就不能声明引用的引用，也不能定义引用的指针。（5）不能建立数组的引用，因为数组是一个由若干个元素所组成的集合，所以就无法建立一个数组的别名。（6）不能建立空指针的引用。（7）不能建立空类型void的引用。（8）尽管引用运算符与地址操作符使用相同的符号，但是不一样的。引用仅在声明时带有引用运算符&amp;，以后就像普通变量一样使用，不能再带&amp;。其他场合使用的&amp;都是地址操作符。 用引用作为函数的参数一个函数的参数可以定义成引用的形式。在主调函数的调用点处，直接以变量作为实参进行调用即可，不需要实参变量有任何的特殊要求。 用引用返回函数值函数可以返回一个引用，将函数说明为返回一个引用。主要目的是：为了将函数用在赋值运算符的左边。要以引用返回函数值。类型标识符 &amp;函数名 (形参列表及类型说明){函数体}（1）以引用返回函数值，定义函数时需要在函数名前加&amp;（2）用引用返回一个函数值的最大好处是，在内存中不产生返回值的副本。在定义返回引用的函数时，注意不要返回该函数内的自动变量（局部变量）的引用，由于自动变量的生存期仅限于函数内部，当函数返回时，自动变量就消失了。 一个返回引用的函数值作为赋值表达式的左值。一般情况下，赋值表达式的左边只能是变量名，即被赋值的对象必须是变量，只有变量才能被赋值。 Lecture 2类的构成数据成员、成员函数 private, protected, public· private 部分称为类的私有部分，这一部分的数据成员和成员函数称为类的私有成员。私有成员只能由本类的成员函数访问，而类外部的任何访问都是非法的。（只能在定义、实现的时候访问）· public 部分称为类的共有部分，这部分的数据成员和成员函数称为类的公有成员。公有成员可以由程序中的函数访问，它对外是完全开放的。· protected 部分称为类的保护部分，这部分的数据成员和成员函数称为类的保护成员。保护成员可以由本类的成员函数访问，也可以由本类的派生类的成员函数访问，而类外的任何访问都是非法的。 （1）类声明格式中的3个部分并非一定要全有，但至少要有其中的一个部分。一般一个类的数据成员应该声明为私有成员，成员函数声明为公有成员。（2）类声明中的private, protected, public三个关键字可以按任意顺序出现任意次。但是，如果把所有的私有成员、保护成员和公有成员归类放在一起，程序将更加清晰。（3）private处于类体重第一部分时，关键字private可以省略。（4）数据成员可以是任何数据类型，但不能用自动(auto)、寄存器(register)或外部(extern)进行声明。（5）不能在类声明中给数据成员赋值。C++规定，只有在类对象定义之后才能给数据成员赋初值。 类成员的访问属性类的成员对类对象的可见性和对类的成员函数的可见性是不同的。类的成员函数可以访问类的所有成员，而类的对象对类的成员的访问是受类成员的访问属性的制约的。 一般来说，公有成员是类的对外接口，而私有成员和保护成员是类的内部数据和内部实现，不希望外界访问。将类的成员划分为不同的访问级别有两个好处：一是信息隐蔽，即实现封装；二是数据保护，即将类的重要信息保护起来，以免其他程序不恰当地修改。 对象赋值语句两个同类型的变量之间可以相互赋值。同类型的对象间也可以进行赋值，当一个对象赋值给另一个对象时，所有的数据成员都会逐位拷贝。说明：·在使用对象赋值语句进行对象赋值时，两个对象的类型必须相同，如果对象的类型不同，编译时将出错。·两个对象之间的赋值，仅仅使这些对象中数据成员相同，而两个对象仍是分离的。·=的对象赋值是通过缺省的赋值运算符函数实现的。（复杂的需要重载）·当类中存在指针时，使用缺省的赋值运算符进行对象赋值，可能会产生错误。 Lecture 3构造函数与析构函数构造函数和析构函数都是类的成员函数，但它们都是特殊的成员函数，执行特殊的功能，不用调用便自动执行，而且这些函数的名字与类的名字有关。C++语言中有一些成员函数性质是特殊的，这些成员函数负责对象的建立、删除。这些函数的特殊性在于可以由编译器自动地隐含调用，其中一些函数调用格式采用运算符函数重载的语法。C++引进一个自动完成对象初始化过程的机制，这就是类的构造函数。 对象的初始化1）数据成员是不能在声明类时初始化2）类型对象的初始化方法：·调用对外接口(public成员函数)实现 声明类→定义对象→调用接口给成员赋值·应用构造函数(constructor)实现 声明类→定义对象→同时给成员赋值 构造函数构造函数是一种特殊的成员函数，它主要用于为对象分配空间，进行初始化。构造函数具有一些特殊的性质：（1）构造函数的名字必须与类名相同。（2）构造函数可以有任意类型的参数，但不能指定返回类型。它有隐含的返回值，该值由系统内部使用。（3）构造函数是特殊的成员函数，函数体可写在类体内，也可写在类体外。（4）构造函数可以重载，即一个类中可以定义多个参数个数或参数类型不同的构造函数。构造函数是不能继承。（5）构造函数被声明为公有函数，但它不能像其他成员函数那样被显式地调用，它是在定义对象的同时调用的·在声明类时如果没有定义类的构造函数，编译系统就会在编译时自动生成一个默认形式的构造函数。·默认构造函数是构造对象时不提供参数的构造函数。·除了无参数构造函数是默认构造函数外，带有全部默认参数值的构造函数也是默认构造函数。·自动调用：构造函数在定义类对象时自动调用，不需用户调用，也不能被用户调用。在对象使用前调用。·调用顺序：在对象进入其作用域时（对象使用前）调用构造函数。 利用构造函数创建对象的两种方法：（1）利用构造函数直接创建对象，其一般形式为：类名 对象名[(实参表)];这里的“类名”与构造函数名相同，“实参表”是为构造函数提供的实际参数。（2）利用构造函数创建对象时，通过指针和new来实现。其一般语法形式为：类名 *指针变量 = new 类名 [(实参表)]; 例2.19 用p2 = p1试一下0.0 析构函数析构函数也是一种特殊的成员函数。它执行与构造函数相反的操作，通常用于撤销对象时的一些清理任务，如释放分配给对象的内存空间等。析构函数有以下一些特点：①析构函数与构造函数名字相同，但它前面必须加一个波浪号(~)；②析构函数没有参数，也没有返回值，而且不能重载。因此在一个类中只能有一个析构函数；③当撤销对象时，编译系统会自动调用析构函数。如果程序员没有定义析构函数，系统将自动生成和调用一个默认析构函数，默认析构函数只能释放对象的数据成员所占用的空间，但不包括堆内存空间。]]></content>
      <tags>
        <tag>learning note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep-learning-note]]></title>
    <url>%2F2018%2F02%2F18%2Fdeep-learning-note%2F</url>
    <content type="text"><![CDATA[Neural Networks and Deep LearningWeek One(Neural network is also introduced in Machine Learning course, with my learning note). House price Prediction can be regarded as the simplest neural network:The function can be ReLU (REctified Linear Unit), which we’ll see a lot. This is a single neuron. A larger neural network is then formed by taking many of the single neurons and stacking them together. Almost all the economic value created by neural networks has been through supervised learning. Input(x) Output(y) Application Neural Network House feature Price Real estate Standard NN Ad, user info Click on ad?(0/1) Online advertising Standard NN Photo Object(Index 1,…,1000) Photo tagging CNN Audio Text transcript Speech recognition RNN English Chinese Machine translation RNN Image, Radar info Position of other cars Autonomous driving Custom/Hybrid Neural Network examplesCNN: often for image dataRNN: often for one-dimensional sequence data Structured data and Unstructured data Scale drives deep learning progressScale: both the size of the neural network and the scale of the data. Data Computation Algorithms Using ReLU instead of sigmoid function as activation function can improve efficiency. Week TwoNotation(x,y): a single training example. x\in\mathbb{R}^{n_x},y\in\{0,1\}m training examples: \{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),...,(x^{(m)},y^{(m)})\} X=\begin{bmatrix}|&|&\ &|\\x^{(1)}&x^{(2)}&...&x^{(m)}\\|&|&\ &|\end{bmatrix}X\in\mathbb{R}^{n_x\times m}Take training set inputs x1, x2 and so on and stacking them in columns. (This make the implementation much easier than X’s transpose) Y=\begin{bmatrix}y^{(1)}&y^{(2)}&...&y^{(m)}\end{bmatrix}Y\in\mathbb{R}^{1\times m}Logistic RegressionDifferences with former courseNotation is a bit different from what is introduced in Machine Learning(note).Originally, we add x_0=1 so that x\in\mathbb{R}^{n_x+1}. \hat{y}=\sigma(\theta^Tx)where \theta=\begin{bmatrix}\theta_0\\\theta_1\\\theta_2\\...\\\theta_{n_x}\end{bmatrix}. Here in Deep Learning course, we use b to represent \theta_0, and w to represent \theta_1,...,\theta_{n_m}. Just keep b and w as separate parameters.Given x, want \hat{y}=P(y=1|x). x\in\mathbb{R}^{n_x},0\le\hat y\le1Parameters: w\in\mathbb{R}^{n_x},b\in\mathbb{R}Output: \hat{y}=\sigma(w^Tx+b)σ() is sigmoid function: \sigma(z)=\frac{1}{1+e^{-z}} Cost Function \mathscr{L}(\hat{y},y)=-(y\log\hat{y}+(1-y)\log(1-\hat{y}))If y=1:\mathscr{L}(\hat{y},y)=-\log\hat{y}If y=0:\mathscr{L}(\hat{y},y)=-\log(1-\hat{y}) Cost function: J(w,b)=\frac{1}{m}\sum_{i=1}^m\mathscr{L}(\hat{y}^{(i)},y^{(i)})=-\frac{1}{m}\sum_{i=1}^m(y^{(i)}\log\hat{y}^{(i)}+(1-y^{(i)})\log(1-\hat{y}^{(i)}))Loss function is applied to just a single training example.Cost function is the cost of your parameters, it is the average of the loss functions of the entire training set. Gradient DescentUsually initialize the value to zero in logistic regression. Random initialization also works, but people don’t usually do that for logistic regression. Repeat { w:=w-\alpha\frac{\partial J(w,b)}{\partial w}b:=b-\alpha\frac{\partial J(w,b)}{\partial b}} From forward propagation, we calculate z, a and finally \mathscr{L}(a,y)From back propagation, we calculate the derivatives step by step: da=\frac{d\mathscr{L}(a,y)}{da}=-\frac{y}{a}+\frac{1-y}{1-a}dz=\frac{d\mathscr{L}(a,y)}{dz}=\frac{d\mathscr{L}}{da}\cdot\frac{da}{dz}=(-\frac{y}{a}+\frac{1-y}{1-a})\cdot a(1-a)=a-ydw_1=\frac{d\mathscr{L}}{dw_1}=x_1\cdot dzdw_2=x_2\cdot dzdb=dzAlgorithm(Repeat)J=0; dw1,dw2,…dwn=0; db=0for i = 1 to m z^{(i)}=w^Tx^{(i)}+ba^{(i)}=\sigma(z^{(i)})J+=-[y^{(i)}\log a^{(i)}+(1-y^{(i)})\log(1-a^{(i)})]dz^{(i)}=a^{(i)}-y^{(i)} for j = 1 to n: dw_j+=x^{(i)}_jdz^{(i)} db+=dz^{(i)}J /= m;dw1,dw2,…,dwn /= m;db /= m w1:=w1-αdw1w2:=w2-αdw2b:=b-αdb In the for loop, there’s no superscript i for dw variable, because the value of dw in the code is cumulative. While dz is referring to one training example. VectorizationOriginal for loop:for i = 1 to m z^{(i)}=w^Tx^{(i)}+ba^{(i)}=\sigma(z^{(i)})Vectorized: Z=\begin{bmatrix}z^{(1)}&z^{(2)}&...&z^{(m)}\end{bmatrix}=w^TX+\begin{bmatrix}b&b&...&b\end{bmatrix}=\begin{bmatrix}w^Tx^{(1)}+b&w^Tx^{(2)}+b&...&w^Tx^{(m)}+b\end{bmatrix}A=\begin{bmatrix}a^{(1)}&a^{(2)}&...&a^{(m)}\end{bmatrix}=\sigma(z)Y=\begin{bmatrix}y^{(1)}&...&y^{(m)}\end{bmatrix}dZ=\begin{bmatrix}dz^{(1)}&dz^{(2)}&...&dz^{(m)}\end{bmatrix}=A-YCode:z = np.dot(w.T, X) + bdz = A - Ycost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))db = 1 / m * np.sum(dZ)dw = 1 / m * X * dZ.T About PythonA.sum(axis = 0): sum verticallyA.sum(axis = 1): sum horizontally BroadcastingIf an (m, n) matrix operates with (+-*/) a (1, n) row vector, just expand the vector vertically to (m, n) by copying m times.If an (m, n) matrix operates with a (m, 1) column vector, just expand the vector horizontally to (m, n) by copying n times.If an row/column vector operates with a real number, just expand the real number to the corresponding vector.documention Rank 1 Arraya = np.random.randn(5) creates a rank 1 array whose shape is (5,).Try to avoid using rank 1 array. Use a = a.reshape((5, 1)) or a = np.random.randn(5, 1). Note that np.dot() performs a matrix-matrix or matrix-vector multiplication. This is different from np.multiply() and the * operator (which is equivalent to .* in MATLAB/Octave), which performs an element-wise multiplication. Week ThreeNeural Network OverviewSuperscript with square brackets denotes the layer, superscript with round brackets refers to i’th training example. Logistic regression can be regarded as the simplest neural network. The neuron takes in the inputs and make two computations: z=w^Tx+b$,a=\sigma(z) Neural network functions similarly. (Note that this neural network has 2 layers. When counting layers, input layer is not included.)Take the first node in the hidden layer as example: z^{[1]}_1=w_1^{[1]T}x+b^{[1]}_1a^{[1]}_1=\sigma(z^{[1]}_1)The superscript [l] denotes the layer, and subscript i represents the node in layer.Similarly, z^{[1]}_2=w_2^{[1]T}x+b^{[1]}_2a^{[1]}_2=\sigma(z^{[1]}_2)z^{[1]}_3=w_1^{[1]T}x+b^{[1]}_3a^{[1]}_3=\sigma(z^{[1]}_3)z^{[1]}_4=w_1^{[1]T}x+b^{[1]}_4a^{[1]}_4=\sigma(z^{[1]}_4)Vectorization: z^{[1]}=\begin{bmatrix}-&w_1^{[1]}&-\\-&w_2^{[1]}&-\\-&w_3^{[1]}&-\\-&w_4^{[1]}&-\end{bmatrix}\begin{bmatrix}x_1\\x_2\\x_3\end{bmatrix}+\begin{bmatrix}b_1^{[1]}\\b_2^{[1]}\\b_3^{[1]}\\b_4^{[1]}\end{bmatrix}=\begin{bmatrix}w_1^{[1]T}x+b_1^{[1]}\\w_2^{[1]T}x+b_2^{[1]}\\w_3^{[1]T}x+b_3^{[1]}\\w_4^{[1]T}x+b_4^{[1]}\end{bmatrix}=\begin{bmatrix}z^{[1]}_1\\z^{[1]}_2\\z^{[1]}_3\\z^{[1]}_4\end{bmatrix}a^{[1]}=\begin{bmatrix}a_1^{[1]}\\a^{[1]}_2\\a^{[1]}_3\\a^{[1]}_4\end{bmatrix}=\sigma(z^{[1]})Formula: z^{[1]}=W^{[1]}a[0]+b^{[1]}a^{[1]}=\sigma(z^{[1]})z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}a^{[2]}=\sigma(z^{[2]})(dimensions: z^{[1]}:(4,1),W^{[1]}:(4,3),a^{[0]}:(3,1),b^{[1]}:(4,1),a^{[1]}:(4,1);z^{[2]}:(1,1),W^{[2]}:(1,4),b^{[2]}:(1,1),a^{[2]}:(1,1)) Vectorizing across multiple examples: Z^{[1]}=W^{[1]}X+b^{[1]}A[1]=\sigma(Z^{[1]})Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}A^{[2]}=\sigma(Z^{[2]})ExplanationStack elements in column.Each column represents a training example, each row represents a hidden unit. Activation FunctionSigmoid Function a=\frac{1}{1+e^{-z}}Only used in binary classification’s output layer(with output 0 or 1).Not used in other occasion. tanh is a better choice. g'(z)=\frac{d}{dz}g(z)=\frac{1}{1+e^{-z}}(1-\frac{1}{1+e^{-z}})=a(1-a)tanh Function a=\tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}With a range of (-1,1), it performs better than sigmoid function because the mean of its output is closer to zero.Both sigmoid and tanh function have a disadvantage that when z is very large(\to\infty) or very small(\to-\infty), the derivative can be close to 0, so the gradient descent would be very slow. g'(z)=\frac{d}{dz}g(z)=1-(tanh(z)^2)=1-a^2ReLU a=\max(0,z)Default choice of activation function.With g'(z)=1 when z is positive, it performs well in practice.(Although the g&#39;(z)=0 when z is positive, and technically the derivative when z=0 is not well-defined) Leaky ReLU a=\max(0.01z,z)Makes sure that derivatives not equal to 0 when z &lt; 0. Linear Activation Function g(z)=zAlso called identity function.Not used in neural network, because even many hidden layers still gets a linear result. Just used in machine learning when the output is a real number. Gradient descentForward propagation: Z^{[1]}=W^{[1]}X+b^{[1]}A^{[1]}=g^{[1]}(Z^{[1]})Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}A^{[2]}=g^{[2]}(Z^{[2]})Backward propagation: dZ^{[2]}=A^{[2]}-YdW^{[2]}=\frac{1}{m}dZ^{[2]}A^{[1]T}db^{[2]}=\frac{1}{m}np.sum(dZ^{[2]},axis=1,keepdims=True)dZ^{[1]}=W^{[2]T}dZ^{[2]}*g^{[1]'}(Z^{[1]})dW^{[1]}=\frac{1}{m}dZ^{[1]}X^Tdb^{[1]}=\frac{1}{m}np.sum(dZ^{[1]},axis=1,keepdims=True)note:keepdims=True makes sure that Python won’t produce rank-1 array with shape of (n,).* is element-wise product. dZ^{[1]}:(n[1],m);W^{[2]T}dZ^{[2]}:(n[1],m);g^{[1]'}(Z^{[1]}):(n[1],m). Random InitializationIn logistic regression, it’s okay to initialize all parameters to zero. However, it’s not feasible in neural network.Instead, initialize w with random small value to break symmetry. It’s okay to initialize b to zeros. Symmetry is still broken so long as W^{[l]} is initialized randomly. 1234W1 = np.random.randn((2, 2)) * 0.01b1 = np.zeros((2, 1))W2 = np.random.randn((1, 2)) * 0.01b2 = 0 RandomIf the parameter w are all zeros, then the neurons in hidden layers are symmetric(“identical”). Even if after gradient descent, they keep the same. So use random initialization. SmallBoth sigmoid and tanh function has greatest derivative at z=0. If z had large or small value, the derivative would be close to zero, and consequently gradient descent would be slow. Thus, it’s a good choice to make the value small. Week FourDeep neural network notation-l: number of layers-n^{[l]}: number of units in layer l-a^{[l]}: activations in layer l. a^{[l]}=g^{[l]}(z^{[l]})(a^{[0]}=x, a^{[l]}=\hat{y})-W^{[l]}: weights for z^{[l]}-b^{[l]}: bias for z^{[l]} Forward Propagationfor l = 1 to L: Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}A^{[l]}=g^{[l]}(Z^{[l]})Well, this for loop is inevitable. Matrix Dimensions-W^{[l]}=dW^{[l]}:(n^{[l]},n^{[l-1]})-b^{[l]}=db^{[l]}:(n^{[l]},m)(here the dimension can be (n^{[l]},1) with Python’s broadcasting)-Z^{[l]}=A^{[l]}:(n^{[l]},m)-dZ^{[l]}=dA^{[l]}=Z^{[l]}=A^{[l]} cacheCache is used to pass variables computed during forward propagation to the corresponding backward propagation step. It contains useful values for backward propagation to compute derivatives. Why deep representations?Informally: There are functions you can compute with a “small” L-layer deep neural network that shallower networks require exponentially more hidden units to compute. Forward and Backward PropagationForward propagation for layer lInput a^{[l-1]}Output a^{[l]}, cache (z^{[l]}) Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}A^{[l]}=g^{[l]}(Z^{[l]})Backward propagation for layer lInput da^{[l]}Output da^{[l-1]},dW^{[l]},db^{[l]} dZ^{[l]}=dA^{[l]}*g^{[l]'}(Z^{[l]})dW^{[l]}=\frac{1}{m}dZ^{[l]}A^{[l-1]T}db^{[l]}=\frac{1}{m}np.sum(dZ^{[l]},axis=1,keepdims=True)dA^{[l-1]}=W^{[l]T}dZ^{[l]}Hyperparameters and ParametersHyperparameters determine the final value parameters. Parameters· W^{[1]},b^{[1]},W^{[2]},b^{[2]},W^{[3]},b^{[3]}... Hyperparameters· learning rate \alpha· number of iterations· number of hidden layers L· number of hidden units n^{[1]},n^{[2]},...· choice of activation function· momentum, minibatch size, regularizations, etc. Improving Deep Neural Networks: Hyperparameter tuning, Regularization and OptimizationWeek OneSetting up your Machine Learning ApplicationTrain/dev/test setsTraining set:Keep on training algorithms on the training sets. Development setAlso called Hold-out cross validation set, Dev set for short.Use dev set to see which of many different models performs best on the dev set. Test setTo get an unbiased estimate of how well your algorithm is doing. ProportionPrevious era: the data amount is not too large, it’s common to take all the data and split it as 70%/30% or 60%/20%/20%.Big data: there’re millions of examples, 10000 examples used in dev set and 10000 examples used in test set is enough. The proportion can be 98/1/1 or even 99.5/0.4/0.1 NotesMake sure dev set and test set come from same distribution. Not having a test set might be okay if it’s not necessary to get an unbiased estimate of performance. Though dev set is called ‘test set’ if there’s no real test set. Bias/VarianceSolutionsHigh bias:Bigger networkTrain longer(Neural network architecture search) High variance:More dataRegularization(Neural network architecture search) Bias Variance trade-offOriginally, reducing bias may increase variance, and vice versa. So it’s necessary to trade-off between bias and variance.But in deep learning, there’re ways to reduce one without increasing another. So don’t worry about bias variance trade-off. RegularizationL2 RegularizationLogistic regression J(w,b)=\frac{1}{m}\sum_{i=1}^m\mathscr{L}(\hat{y},y^{(i)})+\frac{\lambda}{2m}||w||_2^2L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes.Weights end up smaller(“weight decay”): Weights are pushed to smaller values.L2 regularization: ||w||_2^2=\sum_{j=1}^{n_x}w_j^2=w^TwL1 regularization: ||w||_1=\sum_{j=1}^{n_x}|w_j|(L1 regularization leads w to be sparse, but not very effictive) Neural network J(w^{[1]},b^{[1]},...,w^{[L]},b^{[L]})=\frac{1}{m}\sum_{i=1}^m\mathscr{L}(\hat{y},y^{(i)})+\frac{\lambda}{2m}\sum_{l=1}^L||w^{[l]}||_F^2-||w^{[l]}||_F^2=\sum_{i=1}^{n^{[l]}}\sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^2, it’s called Frobenius norm which is different from Euclidean distance. Back propagation: dW^{[l]}=(from\ backprop)+\frac{\lambda}{m}W^{[l]}W^{[l]}:=W^{[l]}-\alpha dW^{[l]}Dropout regularizationWith dropout, what we’re going to do is go through each of the layers of the network and set some probability of eliminating a node in neural network.For each training example, you would train it using one of these neural based networks.The idea behind drop-out is that at each iteration, you train a different model that uses only a subset of your neurons. With dropout, your neurons thus become less sensitive to the activation of one other specific neuron, because that other neuron might be shut down at any time.Usually used in Computer Vision. Implementation with layer 3 123d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_prob # boolean matrix with 0/1a3 = np.multiply(a3, d3) # a3 *= d3, element-wise multiplya3 /= keep_prob # ensures that the expected value of a3 remains the same. Make test time easier because of less scaling problem Dropout is a regularization technique. You only use dropout during training. Don’t use dropout (randomly eliminate nodes) during test time. Apply dropout both during forward and backward propagation. During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. You can check that this works even when keep_prob is other values than 0.5. Other regularization methodsData augmentationTake image input for example. Flipping the image horizontally, rotating and sort of randomly zooming, distortion, etc.Get more training set without paying much to reduce overfitting. Early stoppingStop early so that ||w||_F^2 is relatively small.Early stopping violates Orthogonalization, which suggests separate Optimize cost function J and Not overfit. OptimizationNormalizing inputsSubtract mean \mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}x:=x-\muNormalize variance \sigma^2=\frac{1}{m}\sum_{i=1}^mx^{(i)}**2x/=\sigma^2Note: use same \mu,\sigma^2 to normalize test set. Intuition: Vanishing/Exploding gradientsSince the number of layers in deep learning may be quite large, the product of L layers may tend to \infty or 0. (just think about 1.001^{1000} and 0.999^{1000}) Weight initialization for deep networksTake a single neuron as example: z=w_1x_1+w_2x_2+...+w_nx_nIf n is large, then w_i would be smaller. Our goal is to get Var(w:)=\frac{1}{n}or\frac{2}{n} Random initialization for ReLU:(known as He initialization, named for the first author of He et al., 2015.) W^{[l]}=np.random.randn(shape.)*np.sqrt(\frac{2}{n^{[l-1]}})For tanh: use \sqrt(\frac{1}{n^{[l-1]}})Xavier initialization: \sqrt(\frac{2}{n^{[l-1]}+n^{[l]}}) Gradient checkingg(\theta)=\frac{f(\theta+\epsilon)-f(\theta-\epsilon)}{2\epsilon}Take W^{[1]},b^{[1]},...,W^{[L]},b^{[L]} and reshape into a big vector \theta: J(W^{[1]},b^{[1]},...,W^{[L]},b^{[L]})=J(\theta)Take dW^{[1]},db^{[1]},...,dW^{[L]},db^{[L]} and reshape into a big vector d\theta for each i: -d\theta_{approx}[i]=\frac{J(\theta_1,\theta_2,...,\theta_i+\epsilon,...)-J(\theta_1,\theta_2,...,\theta_i-\epsilon,...)}{2\epsilon} check if d\theta_{approx}\approx d\theta?Calculate \frac{||d\theta_{approx}-d\theta||_2}{||d\theta_{approx}||_2+||d\theta||}. (10^{-7} is great) NoteGradient checking verifies closeness between the gradients from backpropagation and the numerical approximation of the gradient (computed using forward propagation).Gradient checking is slow, so we don’t run it in every iteration of training. You would usually run it only to make sure your code is correct, then turn it off and use backprop for the actual learning process. Don’t use in training - only to debug. If algorithm fails grad check, look at components to try to identify bug. Remember regularization. Doesn’t work with dropout. Run at random initialization; perhaps again after some training. Week TwoMini-batch gradient descentBatch gradient descent (original gradient descent that we’ve known) calculates the entire training set, and just update the parameters W,b a little step. If the training set is pretty large, the training would be quite slow. And the idea of mini-batch gradient descent is use part of the training set, and update the parameters faster.For example, if X‘s dimension is (n_x,m), divide the training set into parts with dimension of (n_x,1000), i.e. X^{\{1\}}=[x^{(1)}\ x^{(2)}\ ...\ x^{(1000}],X^{\{2\}}=[x^{(1001)}\ x^{(1002)}\ ...\ x^{(2000)}],...Similarly, Y^{\{1\}}=[y^{(1)}\ y^{(2)}\ ...\ y^{(1000}],Y^{\{2\}}=[y^{(1001)}\ y^{(1002)}\ ...\ y^{(2000)}],....One iteration of mini-batch gradient descent(computing on a single mini-batch) is faster than one iteration of batch gradient descent. Two steps of mini-batch gradient descent: repeat { for t = 1,…,5000 { Forward prop on X^{\{t\}} Z^{[1]}=W^{[1]}X^{\{t\}}+b^{[1]} A^{[1]}=g^{[1]}(Z^{[1]}) … A^{[L]}=g^{[L]}(Z^{[L]}) Compute cost J^{\{t\}}=\frac{1}{1000}\sum_{i=1}^l\mathscr{L}(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2*1000}\sum_l||W^{[l]}||_F^2) Backprop to compute gradients cost J^{\{t\}} (using (X^{\{t\}},Y^{\{t\}})) W^{[l]}:=W^{[l]}-\alpha dW^{[l]},b^{[l]}:=b^{[l]}-\alpha db^{[l]} } # this is called 1 epoch} Choosing mini-batch sizeMini-batch size = m: Batch gradient descent. (X^{\{1\}},Y^{\{1\}})=(X,Y)It has to process the whole training set before making progress, which takes too long for per iteration. Mini-batch size = 1: Stochastic gradient descent. (X^{\{1\}},Y^{\{1\}})=(X^{(1)},Y^{(1)})It loses the benefits of vectorization across examples. Mini-batch size in between 1 and m.Fastest learning: using vectorization and make process without processing entire training set. If training set is small(m≤2000): just use batch gradient descent.Typical mini-batch sizes: 64, 128, 256, 512 (1024) Exponentially weighted averagesv_t=\beta v_{t-1}+(1-\beta)\theta_tE.g.-v_{100}=0.9v_{99}+0.1\theta_{100}-v_{99}=0.9v_{98}+0.1\theta_{99}-v_{98}=0.9v_{97}+0.1\theta_{98}-...Replace v_{99} with the second equation, then replace v_{98} with the third equation, and so on. Finally we’d get v_{100}=0.1\theta_{100}+0.1*0.9\theta_{99}+0.1*0.9^2\theta_{98}+...+0.1*0.9^{99}\theta_1This is why it is called exponentially weighted averages. In practice, 0.9^{10}\approx0.35\approx\frac{1}{e}, thus it show an average of 10 examples. Bias correctionAs is shown above, the purple line is exponentially weighted average without bias correction, it’s much lower than the exponentially weighted average with bias correction(green line) at the very beginning.Since v_0 is set to be zero(and assume \beta=0.98), the first calculation v_1=0.98v_0+0.02\theta_1 has quite small result. The result is small until t gets larger(say t=50 for \beta=0.98) To avoid such situation, bias correction introduces another step: \frac{v_t}{1-\beta^t}Gradient descent with momentumSet v_{dW}=0,v_{db}=0On iteration t: Compute dW,db on the current mini-batch v_{dW}=\beta v_{dW}+(1-\beta)dW v_{db}=\beta v_{db}+(1-\beta)db W=W-\alpha v_{dW},b=b-\alpha v_{db} Momentum takes past gradients into account to smooth out the steps of gradient. Gradient descent with momentum has the same idea as exponentially weighted average(while some may not use (1-\beta) in momentum). Just as the example shown above, we want slow learning horizontally and faster learning vertically. The exponentially weighted average helps to eliminate the horizontal oscillation and makes gradient descent faster. Note there’s no need for gradient descent with momentum to do bias correction. After several iterations, the algorithm will be okay. RMSpropOn iteration t: Compute dW,db on the current mini-batch s_{dW}=\beta_2S_{dW}+(1-\beta)dW^2 s_{db}=\beta_2S_{db}+(1-\beta)db^2 W:=W-\alpha\frac{dW}{\sqrt{s_{dW}+\epsilon}},b:=b-\alpha\frac{db}{\sqrt{s_{db}+\epsilon}} RMS means Root Mean Square, it uses division to help to adjust gradient descent. Adam optimization algorithmCombine momentum and RMSprop together:1.It calculates an exponentially weighted average of past gradients, and stores it in variable v (before bias correction) and v_corrected (with bias correction).2.It calculates an exponentially weighted average of the squares of the past gradients, and stores it in variable s (before bias correction) and s_corrected (with bias correction).3.It updates parameters in a direction based on combining information from 1 and 2. Set v_{dW}=0,S_{dW}=0,v_{db}=0,S_{db}=0On iteration t: Compute dW,db on the current mini-batch v_{dW}=\beta_1v_{dW}+(1-\beta_1)dW,v_{db}=\beta_1V_{db}+(1-\beta_1)db s_{dW}=\beta_2s_{dW}+(1-\beta_2)dW^2,s_{db}=\beta_2S_{db}+(1-\beta_2)db^2 v_{dW}^{corrected}=v_{dW}/(1-\beta^t_1),v_{db}^{corrected}=v_{db}/(1-\beta^t_1) s_{dW}^{corrected}=s_{dW}/(1-\beta^t_2),s_{db}^{corrected}=s_{db}/(1-\beta_2^t) W:=W-\alpha\frac{V_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\epsilon},b:=b-\alpha\frac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\epsilon} Hyperparameters:-\alpha: needs to be tune-\beta_1: 0.9-\beta_2: 0.999-\epsilon$:10^{-8} (Adam just means Adaption moment estimation) Learning rate decayMini-batch gradient descent won’t converge, but step around at the optimal instead. To help converge, it’s advisable to decay learning rate with the number of iterations.Some formula:-\alpha=\frac{1}{1+decay-rate*epoch-num}\alpha_0-\alpha=0.95^{epoch-num}\alpha_0-\alpha=\frac{k}{\sqrt{epoch-num}}\alpha_0-discrete stair case (half α after some iterations)-manual decay Week ThreeHyperparameter tuningHyperparameters: \alpha,\beta,\beta_1,\beta_2,\epsilon, number of layers, number of units, learning rate decay, mini-batch size, etc.Priority: \alpha>\beta,\#hidden\ units,mini-batch\ size>\#layers,learning\ rate\ decay Try to use random values of hyperparameters rather than grid.Coarse to fine: if finds some region with good result, try more in that region. Appropriate scale:It’s okay to sample uniformly at random for some hyperparameters: number of layers, number of units.While for some hyperparameters like \alpha,\beta, instead of sampling uniformly at random, sample randomly on logarithmic scale. Pandas &amp; CaviarPanda: babysitting one model at a timeCaviar: training many models in parallelLargely determined by the amount of computational power you can access. Batch NormalizationUsing the idea of normalizing input, make normalization in hidden layers. Given some intermediate value in neural network z^{(1)},...,z^{(m)}(specifically z^{[l](i)} in a single layer) \mu=\frac{1}{m}\sum_iz^{(i)} \sigma^2=\frac{1}{m}\sum_i(z^{(i)}-\mu)^2 z^{(i)}_{norm}=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}} \tilde{z}^{(i)}=\gamma z_{norm}^{(i)}+\betaUse \tilde{z}^{[l](i)} instead of z^{[l](i)} Batch Norm as regularizationEach mini-batch is scaled by the mean/variance computed on just that mini-batch.This adds some noise to the values z^{[l]} within that mini-batch. So similar to dropout, it adds some noise to each hidden layer’s activations.This has a slight regularization effect. Batch Norm at test time: use exponentially weighted averages to compute average \mu,\sigma^2 for test. Multi-class classificationSoftmaxThe output layer is a vector with dimension C rather than a real number. C is the number of classes.Activation function: t=e^{(z^{[L]})}a^{[L]}=\frac{e^{z^{[L]}}}{\sum_{j=1}^Ct_j}Cost function \mathscr{L}(\hat{y},y)=-\sum_{j=1}^Cy_j\log\hat{y_j}J(W^{[1]},b^{[1]},...)=\frac{1}{m}\sum_{i=1}^m\mathscr{L}(\hat{y},y)Deep Learning frameworks Caffe/Caffe2 CNTK DL4J Keras Lasagne mxnet PaddlePaddle TensorFlow Theano Torch Choosing deep learning frameworksEasy of programming (development and deployment)Running speedTruly Open (open source with good governance) TensorFlowWriting and running programs in TensorFlow has the following steps: Create Tensors(variables) that are not yet executed/evaluated. Write operations between those Tensors. Initialize your Tensors. Create a Session. Run the Session. This will run the operations you’d written above. tf.constant(...): to create a constant valuetf.placeholder(dtype = ..., shape = ..., name = ...): a placeholder is an object whose value you can specify only later tf.add(..., ...): to do an additiontf.multiply(..., ...): to do a multiplicationtf.matmul(..., ...): to do a matrix multiplication 2 typical ways to create and use sessions in TensorFlow: 1234sess = tf.Session()# Run the variables initialization (if needed), run the operationsresult = sess.run(..., feed_dict = &#123;...&#125;)sess.close() # Close the session 1234with tf.Session() as sess: # run the variables initialization (if needed), run the operations result = sess.run(..., feed_dict = &#123;...&#125;) # This takes care of closing the session Structuring Machine Learning ProjectsWeek OneOrthogonalizationOrthogonalization or orthogonality is a system design property that assures that modifying an instruction or a component of an algorithm will not create or propagate side effects to other components of the system. It becomes easier to verify the algorithms independently from one another, and it reduces testing and development time. When a supervised learning system is designed, these are the 4 assumptions that need to be true and orthogonal. Fit training set well on cost function - bigger network, Adam, etc Fit dev set well on cost function - regularization, bigger training set, etc Fit test set well on cost function - bigger dev set Performs well in real world - change dev set or cost function Single number evaluation metricPrecision Precision(\%)=\frac{True\ positive}{Number\ of\ predicted\ positive}\times100=\frac{True\ positive}{True\ positive+False\ positive}\times100Among all the prediction, estimate how much predictions are right. Recall Recall(\%)=\frac{True\ positive}{Number\ of\ predicted\ actually\ positive}\times100=\frac{True\ positive}{True\ positive+False\ negative}\times100Among all the positive examples, estimate how much positive examples are correctly predicted. F1-Score F1\_Score=\frac{2}{\frac{1}{p}+\frac{1}{r}}The problem with using precision/recall as the evaluation metric is that you are not sure which one is better since in this case, both of them have a good precision et recall. F1-score, a harmonic mean, combine both precision and recall. Satisficing and optimizing metricThere are different metrics to evaluate the performance of a classifier, they are called evaluation matrices. They can be categorized as satisficing and optimizing matrices. It is important to note that these evaluation matrices must be evaluated on a training set, a development set or on the test set.The general rule is: N_{metric}=\begin{cases}1&\text{Optimizing metric}\\N_{metric}-1 &\text{Satisficing metric}\end{cases}For example: Classifier Accuracy Running Time A 90% 80ms B 92% 95ms C 95% 1500ms For example, there’re two evaluation metrics: accuracy and running time. Take accuracy as optimizing metric and the following(running time) as satisficing metric(s). The satisficing metric has to meet expectation set and improve the optimizing metric as much as possible. Train/Dev/Test SetIt’s important to choose the development and test sets from the same distribution and it must be taken randomly from all the data.Guideline: Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on. SizeOld way of splitting data:We had smaller data set, therefore, we had to use a greater percentage of data to develop and test ideas and models. Modern era - Big data:Now, because a larger amount of data is available, we don’t have to compromise and can use a greater portion to train the model. Set your dev set to be big enough to detect differences in algorithms/models you’re trying out.Set your test set to be big enough to give high confidence in the overall performance of your system. When to change dev/test sets and metrics Orthogonalization:How to define a metric to evaluate classifiers.Worry separately about how to do well on this metric. If doing well on your metric + dev/test set does not correspond to doing well on your application, change your metric and/or dev/test set. Comparing to human-level performanceThe graph shows the performance of humans and machine learning over time.Machine learning progresses slowly when it surpasses human-level performance. One of the reason is that human-level performance can be close to Bayes optimal error, especially for natural perception problem.Bayes optimal error is defined as the best possible error. In other words, it means that any functions mapping from x to y can’t surpass a certain level of accuracy(for different reasons, e.g. blurring images, audio with noise, etc). Humans are quite good at a lot of tasks. So long as machine learning is worse than humans, you can: Get labeled data from humans Gain insight from manual error analysis: Why did a person get this right? Better analysis of bias/variance Human-level error as a proxy for Bayes error(i.e. Human-level error ≈ Bayes error).The difference between Human-level error and training error is also regarded as “Avoidable bias”. If the difference between human-level error and the training error is bigger than the difference between the training error and the development error. The focus should be on bias reduction technique.· Train bigger model· Train longer/better optimization algorithms(momentum, RMSprop, Adam)· NN architecture/hyperparameters search(RNN,CNN) If the difference between training error and the development error is bigger than the difference between the human-level error and the training error. The focus should be on variance reduction technique· More data· Regularization(L2, dropout, data augmentation)· NN architecture/hyperparameters search Problems where machine significantly surpasses human-level performanceFeature: Structured data, not natural perception, lots of data.· Online advertising· Product recommendations· Logistics(predicting transit time)· Loan approvals The two fundamental assumptions of supervised learning:You can fit the training set pretty well.(avoidable bias ≈ 0)The training set performance generalizes pretty well to the dev/test set.(variance ≈ 0) Week TwoError AnalysisSpread sheet:Before deciding how to improve the accuracy, set up a spread sheet find out what matters.For example: Image Dog Great Cat Blurry Comment 1 √ small white dog 2 √ √ lion in rainy day … Percentage 5% 41% 63% Mislabeled examples refer to if your learning algorithm outputs the wrong value of Y.Incorrectly labeled examples refer to if in the data set you have in the training/dev/test set, the label for Y, whatever a human label assigned to this piece of data, is actually incorrect. Deep learning algorithms are quite robust to random errors in the training set, but less robust to systematic errors. Guideline: Build system quickly, then iterate. Set up development/test set and metrics Set up a target Build an initial system quickly Train training set quickly: Fit the parameters Development set: Tune the parameters Test set: Assess the performance Use bias/variance analysis &amp; Error analysis to prioritize next steps Mismatched training and dev/test setThe development set and test should come from the same distribution. However, the training set’s distribution might be a bit different. Take a mobile application of cat recognizer for example:The images from webpages have high resolution and are professionally framed. However, the images from app’s users are relatively low and blurrier.The problem is that you have a different distribution:Small data set from pictures uploaded by users. (10000)This distribution is important for the mobile app.Bigger data set from the web.(200000) Instead of mixing all the data and randomly shuffle the data set, just like below.Take 5000 examples from users into training set, and halving the remaining into dev and test set. The advantage of this way of splitting up is that the target is well defined.The disadvantage is that the training distribution is different from the dev and test set distributions. However, the way of splitting the data has a better performance in long term. Training-Dev SetSince the distributions among the training and the dev set are different now, it’s hard to know whether the difference between training error and the training error is caused by variance or from different distributions.Therefore, take a small fraction of the original training set, called training-dev set. Don’t use training-dev set for training, but to check variance.The difference between the training-dev set and the dev set is called data mismatch. Addressing data mismatch: Carry out manual error analysis to try to understand difference between training and dev/test sets. Make training data more similar; or collect more data similar to dev/test sets Transfer learning When transfer learning makes sense: Task A and B have the same input x. You have a lot more data for Task A than Task B. Low level features from A could be helpful for learning B. Guideline: Delete last layer of neural network Delete weights feeding into the last output layer of the neural network Create a new set of randomly initialized weights for the last layers only New data set (x,y) Multi-task learningExample: detect pedestrians, cars, road signs and traffic lights at the same time. The output is a 4-dimension vector.Note that the second sum(j = 1 to 4) only over value of j with 0/1 label (not ? mark). When multi-task learning makes sense Training on a set of tasks that could benefit from having shared lower-level features. Usually: Amount of data you have for each task is quite similar. Can train a big enough neural network to do well on all the tasks. End-to-end deep learningEnd-to-end deep learning is the simplification of a processing or learning systems into one neural network. End-to-end deep learning cannot be used for every problem since it needs a lot of labeled data. It is used mainly in audio transcripts, image captures, image synthesis, machine translation, steering in self-driving cars, etc. Pros and cons of end-to-end deep learningPros:Let the data speakLess hand-designing of components needed Cons:May need large amount of dataExcludes potentially useful hand-designed components Convolutional Neural NetworksWeek OneComputer Vision Problems Image Classification Object Detection Neural Style Transfer Convolution * is the operator for convolution. Filter/KernelThe second operand is called filter in the course and often called kernel in the research paper.There’re different types of filters:Filter usually has an size of odd number. 1*1, 3*3, 5*5...(helps to highlight the centroid) Vertical edge detection examples Valid and Same ConvolutionsSuppose that the original image has a size of n×n, the filter has a size of f×f, then the result has a size of (n-f+1)×(n-f+1). This is called Valid convolution.The size will get smaller and smaller with the process of valid convolution. To avoid such a problem, we can use paddings to enlarge the original image before convolution so that output size is the same as the input size.If the filter’s size is f×f, then the padding p=\frac{f-1}{2}. The main benefits of padding are the following:· It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the “same” convolution, in which the height/width is exactly preserved after one layer.· It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image. StrideThe simplest stride is 1, which means that the filter moves 1 step at a time. However, the stride can be not 1. For example, moves 2 steps at a time instead. That’s called strided convolution. Given that:Size of n\times n image, f\times f filter, padding p, stride s,output size: \lfloor{\frac{n+2p-f}{s}+1}\rfloor\times\lfloor{\frac{n+2p-f}{s}+1}\rfloortechnicalIn mathematics and DSP, the convolution involves another “flip” step. However, this step is omitted in CNN. The “real” technical note should be “cross-correlation” rather than convolution.In convention, just use Convolution in CNN. Convolution over volumesThe 1-channel filter cannot be applied to RGB images. But we can use filters with multiple channels(RGB images have 3 channels). The number of the filter’s channel should match that of the image’s channel.E.g.A 6\times6\times3 image conv with a 3\times3\times3 filter, the result has a size of 4\times4\times1. Note that this is only 1 channel! (The number of the result’s channel corresponds to the number of the filters). n\times n\times n_c\ *\ f\times f\times n_c\to(n-f+1)\times(n-f+1)\times n_c',n_c'=\#filtersCNNnotationIf layer l is a convolution layer: f^{[l]}= filter size p^{[l]}= padding s^{[l]}= stride n_c^{[l]}= number of filters Each filter is: f^{[l]}\times f^{[l]}\times n_c^{[l-1]}Activations: a^{[l]}\to n_H^{[l]}\times n_w^{[l]}\times n_c^{[l]}, A^{[l]}\to m\times n_H^{[l]}\times n_w^{[l]}\times n_c^{[l]}Weights: f^{[l]}\times f^{[l]}\times n_c^{[l-1]}\times n_c^{[l]},(n_c^{[l]}: #filters in layer l.)bias: n_c^{[l]}-(1,1,1,n_c^{[l]}) n_H^{[l]}=\lfloor{\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1}\rfloor Input: n_H^{[l-1]}\times n_w^{[l-1]}\times n_c^{[l-1]}Output: n_H^{[l]}\times n_w^{[l]}\times n_c^{[l]} E.g. Types of layers in a convolutional network Convolution (conv) Pooling (pool) Fully Connected (FC) Pooling layers Max pooling: slides an (f,f) window over the input and stores the max value of the window in the output. Average pooling: slides an (f,f) window over the input and stores the average value of the window in the output. Hyperparameters:f: filter sizes: strideMax or average poolingNote no parameters to learn. Suppose that the input has a size of n_H\times n_w\times n_c, then after pooling, the output has a size of \lfloor{\frac{n_H-f}{s}+1}\rfloor\times\lfloor{\frac{n_H-f}{s}+1}\rfloor\times n_c A more complicated cnn: Backpropagation is discussed in programming assignment. Why convolutions Parameter sharing: A feature detector(such as a vertical edge detector) that’s useful in one part of the image is probably useful in another part of the image. Sparsity of connections: In each layer, each output value depends only on a small number of inputs. Week TwoClassic networksLeNet - 5Paper link: Gradient-Based Learning Applied to Document Recognition(IEEE has another version of this paper.) Take the input, use a 5×5 filter with 1 stride, then use an average pooling with a 2×2 filter and s = 2. Again, use a 5×5 filter with 1 stride, then use an average pooling with a 2×2 filter and s = 2. After two fully connected layer, the output uses softmax to make classification.conv → pool → conv → pool → fc → fc → outputWith the decrease of nH and nW, the number of nC is increased. AlexNetPaper link: ImageNet Classification with Deep Convolutional Neural Networks Similar to LeNet, but much bigger. (60K -&gt; 60M)It uses ReLU. VGG-16Paper link: Very Deep Convolutional Networks for Large-Scale Image RecognitionCONV = 3×3 filter, s = 1, same(using padding to make the size same)MAX-POOL = 2×2, s = 2Only use these 2 filters. Residual NetworksPaper link: Deep residual networks for image recognition In the plain network, the training error won’t keep decreasing, it may increase at some threshold. In Residual network, the training error will keep decreasing.The skip-connection makes it easy for the network to learn an identity mapping between the input and the output within the ResNet block. In ResNets, a “shortcut” or a “skip connection” allows the gradient to be directly backpropagated to earlier layers: 1×1 convolutionPaper link: Network in network If the input has a volume of dimension n_H\times n_W\times n_C, then a single 1×1 convolutional filter has 1\times1\times n_C+1 parameters(including bias).You can use a 1×1 convolutional layer to reduce n_C but not n_H,n_W.You can use a pooling layer to reduce n_H,n_W, but not n_C. Inception networkPaper link: Going deeper with convolutionsDon’t bother worrying about what filters to use. Use all kinds of filters and stack them together.Module: Typically, with deeper layers, n_H and n_W decrease, while n_C increases. Practical advices for using ConvNetsUsing Open-Source Implementations: GitHub Reasons for using open-source implementations of ConvNet:Parameters trained for one computer vision task are often useful as pretraining for other computer vision tasks.It is a convenient way to get working an implementation of a complex ConvNet architecture. Week ThreeClassification, localization and detectionImage classification: Given a image, make predictions of what classification it is.Classification localization: In addition, put a bounding box to figure out where the object is.Detection: Multiple objects appear in the image, detect all of them. In classification localization, the output has some values b_x, b_y which show the position of the centroid of the object,(note that the upper left corner’s coordinates is (0,0) and the lower right corner’s is (1,1)) and b_h, b_w which show the height and width of the object.If the output has 3 classes, then the format of the output looks like as follows: y=\begin{bmatrix}p_c\\b_x\\b_y\\b_h\\b_w\\c_1\\c_2\\c_3\end{bmatrix}For example, if the image contains a car, then the output is y=\begin{bmatrix}1\\b_x\\b_y\\b_h\\b_w\\0\\1\\0\end{bmatrix}and if the image doesn’t contain anything, the output is y=\begin{bmatrix}0\\?\\?\\?\\?\\?\\?\\?\end{bmatrix}The loss function is \mathscr{L}(\hat y,y)=\begin{cases}(\hat y_1-y_1)^2+&(\hat y_2-y_2)^2+...+(\hat y_8-y_8)^2\text{if y = 1}\\(\hat y_1-y_1)^2 &\text{if y = 0}\end{cases}Landmark detectionThe output contains more information about the position of the landmarks l_x,l_y. Sliding windows detectionUse a small sliding window with small stride scanning the image, detect the objects. Then use a slightly bigger sliding window, and then bigger.However, it has high computation cost. Turning FC layer into convolutional layersUse a filter with the same size of the last layer, the number of filters is the same as the fully connected nodes. YOLOPaper link: You Only Look Once: Unified, Real-Time Object Detection Bounding boxes:Divide the object into several grid cells(in general grids with a size of 19×19 are common), and only detect once if the object’s midpoint is in that grid.Each grid’s upper left corner has a coordinate of (0,0) and lower right corner’s (1,1). Therefore, the value of b_x,b_y should be between (0,1). And b_h,b_w can be greater than 1. IoUIntersection over union IoU=\frac{size\ of\ intersection}{size\ of\ union}If IoU≥0.5 we can estimate that the result is right.More generally, IoU is a measure of the overlap between two bounding boxes. Non-max suppressionAlgorithm:Each output prediction is \begin{bmatrix}p_c\\b_x\\b_y\\b_h\\b_w\end{bmatrix} (just focus on one class at a time so there’s no c_1,c_2)Discard all boxes with p_c\le0.6While there are any remaining boxes:· Pick the box with the largest p_c. Output that as a prediction.· Discard any remaining box with IoU\ge0.5 with the box output in the previous step. Anchor boxesIn an image, some objects may be overlapping. To predict multiple objects in one grid cell, use some anchor boxes. Previously:Each object in training image is assigned to grid cell that contains that object’s midpoint. With two anchor boxes:Each object in training image is assigned to grid cell that contains object’s midpoint and anchor box for the grid cell with highest IoU. The output vector has a size of \#grid\times\#grid\times\#anchors\times(1+4+classes)E.g. y=\begin{bmatrix}p_c\\b_x\\b_y\\b_h\\b_w\\c_1\\c_2\\c_3\\p_c\\b_x\\b_y\\b_h\\b_w\\c_1\\c_2\\c_3\end{bmatrix}(Manually choose the shape of anchor boxes.) Region proposalsPaper link:Rich feature hierarchies for accurate object detection and semantic segmentationInstead using sliding windows over and over again, use segmentation algorithm to predict which regions may contain objects. R-CNN: Propose regions. Classify proposed regions one at a time. Output label + bounding box.Fast R-CNN: Propose regions. Use convolution implementation of sliding windows to classify all the proposed regions.Faster R-CNN: Use convolutional network to propose regions. Week FourFace RecognitionFace verification &amp; Face recognitionVerification:· Input image, name/ID· Output whether the input image is that of the claimed person.This is a 1:1 matching problem. Recognition:· Has a database of K persons· Get an input image· Output ID if the image is any of the K persons(or “not recognized”)This is a 1:K matching problem.(High demand for single accuracy.) Face verification requires comparing a new picture against one person’s face, whereas face recognition requires comparing a new picture against K person’s faces. One-shot learningLearning from one example to recognize the person again. The idea is learning a “similarity” function. (A bit similar to recommendation system.)d(img1, img2) = degree of difference between images.If d(img1,img2)\le\tau, the output is same; else the output is different. Siamese networkParameters of NN define an encoding f(x^{(i)}). (Use a vector to represent the image x)Goal: Learn parameters so thatif x^{(i)},x^{(j)} are the same person, ||f(x^{(i)})-f(x^{(j)})||^2 is small;if x^{(i)},x^{(j)} are different person, ||f(x^{(i)})-f(x^{(j)})||^2 is large. Triplet lossPick an anchor image(denoted as “A”), a positive image(denoted as “P”) and a negative image(denoted as “N”).We can calculate the differences between A and P, A and N. d(A,P)=||f(A)-f(P)||^2,d(A,N)=||f(A)-f(N)||^2We want that d(A,P)=||f(A)-f(P)||^2+\alpha\le d(A,N)=||f(A)-f(N)||^2where α is called margin. Loss function: \mathscr{L}(A,P,N)=\max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+\alpha,0)J=\sum_{i=1}^m\mathscr{L}(A^{(i)},P^{(i)},N^{(i)})About choosing the triplets A,P,NDuring training, if A,P,N are chosen randomly, d(A,P)+\alpha\le d(A,N) is easily satisfied. Therefore, the gradient descent wouldn’t make much progress.Thus, choose triplets that are “hard” to train on. That is, pick A,P,N such that d(A,P)\approx d(A,N) Neural Style TransferNeural style transfer cost functionThe input contains content image(denoted as C) and style image(denoted as S), and the output is the generated image(denoted as G). J(G)=\alpha J_{content}(C,G)+\beta J_{style}(S,G)To find the generated image G:1.Initiate G randomly (e.g. init with white noise)2.Use gradient descent to minimize J(G). G:=G-\frac{\partial}{\partial G}J(G) Content cost function Say you use hidden layer l to compute content cost. Use pre-trained ConvNet. (E.g., VGG network) Let a^{[l](C)} and a^{[l](G)} be the activation of layer l on the images. If a^{[l](C)} and a^{[l](G)} are similar, both images have similar content. J_{content}(C,G)=\frac{1}{2}||a^{[l](C)}-a^{[l](G)}||^2Style cost functionSay you are using layer l‘s activation to measure style.Define style as correlation between activations across channels. Let a^{[l]}_{i,j,k} = activation at (i,j,k). G^{[l]} is n_C^{[l]}\times n_C^{[l]} G^{[l](S)}_{kk'}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{i,j,k}^{[l](S)}a_{i,j,k'}^{[l](S)}G^{[l](G)}_{kk'}=\sum_{i=1}^{n_H^{[l]}}\sum_{j=1}^{n_W^{[l]}}a_{i,j,k}^{[l](G)}a_{i,j,k'}^{[l](G)}The style matrix is also called a “Gram matrix”. In linear algebra, the Gram matrix G of a set of vectors(v_1,...,v_n) is the matrix of dot products, whose entries are G_{ij}=v_i^Tv_j=np.dot(v_i,v_j). In other words, G_{ij} compares how similar v_i is similar to v_j: If they are highly similar, you would expect them to have a large dot product, and thus for G_{ij} to be large. J^{[l]}_{style}(S,G)=\frac{1}{2n_H^{[l]}n_W^{[l]}n_C^{[l]}}||G^{[l](S)}-G^{[l](G)}||^2_F=\frac{1}{2n_H^{[l]}n_W^{[l]}n_C^{[l]}}\sum_k\sum_{k'}(G_{kk'}^{[l](S)}-G_{kk'}^{[l](G)})^2J_{style}(S,G)=\sum_{\lambda}\lambda^{[l]}J_{style}^{[l]}(S,G)The style of an image can be represented using the Gram matrix of a hidden layer’s activations. However, we get even better results combining this representation from multiple different layers. This is in contrast to the content representation, where usually using just a single hidden layer is sufficient.Minimizing the style cost will cause the image G to follow the style of the image S. Sequence ModelWeek OneRecurrent Neural NetworksNotation-x^{}: denotes an object at the t’th timestep.-y^{}: index into the output position-t: implies that these are temporal sequences-T_x: the length of the input sequence-T_y: the length of the output sequence-T_x^{(i)}: the length of the i’th training example-T_y^{(i)}: the output length of the i’th training example-x^{(i)}: the input at the t’th timestep of example i-y^{(i)}: the output at the t’th timestep of example i One-hot representationUsing a large vector(a dictionary containing tens of thousands of words) to represent a word. Only one element is one(the corresponding position of the word in the dictionary) and the others are zero. Why not a standard network?Problems:Inputs, outputs can be different lengths in different examples. (Different sentences have different lengths.)Doesn’t share features learned across different positions of text. (A word may appear many times in a sentence. Need to make repetitions.) RNN cellBasic RNN cell. Takes as input x^{}(current input) and a^{}(previous hidden state containing information from the past), and outputs a^{} which is given to the next RNN cell and also used to predict y^{}. Forward Propagation a^{}=\vec{0}a^{}=g_1(W_{aa}a^{}+W_{ax}x^{}+b_a)\hat{y}^{}=g_2(W_{ya}a^{}+b_y)a^{}=g(W_{aa}a^{}+W_{ax}x^{}+b_a)\hat{y}^{}=g(W_{ya}a^{}+b_y)Here the weight W has two subscripts: the former corresponds to the result and the latter represents the operand that it multiply by. a\leftarrow W_{ax}x The activation function g_1() usually uses tanh, sometimes ReLU.The g_2() function uses sigmoid to make binary classification. The formulas can be simplified as follows: a^{}=g(W_a[a^{},x^{}]+b_a)\hat{y}^{}=g_2(W_ya^{}+b_y)Here, W_a=\begin{bmatrix}W_{aa}&|&W_{ax}\end{bmatrix}, and [a^{},x^{}]=\begin{bmatrix}a^{}\\x^{}\end{bmatrix} Backward Propagation\mathscr{L}^{}(\hat y ^{},y^{})=-y^{}\log\hat y^{}-(1-y^{})\log(1-\hat y^{})\mathscr{L}(\hat y,y)=\sum_{t=1}^{T_x}\mathscr{L}^{}(\hat y^{},y^{})Different typesOne to oneUsage: Simple neural network One to manyUsage: Music generation, sequence generation Many to oneUsage: Sentiment classification Many to many (I)Usage: Name entity recognition Many to many (II)Usage: Machine translation Language model : unknown words (words not shown in vocabulary) : end of sentence Language model is used to calculate the probability using RNN. Each layer’s output is a probability given the previous activations.E.g. given the sentence Cats average 15 hours of sleep a day., \hat y^{}=P(cats) (the probability of ‘cats’ appears in the beginning of the sentence); \hat y^{}=P(average|cat) (conditional probability);…;\hat y^{}=P(|...) Character-level language modelInstead of using words, character-level generates sequences of characters. It’s more computational. Gated Recurrent Unit(GRU)The basic RNN unit: a^{}=g(W_a[a^{},x^{}]+b_a)g() is tanh function. GRU(simplified):Instead of using a^{}, use c^{} instead(though in GRU a^{}=c^{}). Here c represents memory cell. \tilde c^{}=\tanh(W_c[c^{},x^{}]+b_c)\Gamma_u=\sigma(W_u[c^{},x^{}]+b_u)\Gamma_c=\sigma(W_c[c^{},x^{}]+b_c)c^{}=\Gamma_u*\tilde c^{}+(1-\Gamma_u)*c^{}u: update. r: relevance.Gate u is a vector of dimension equal to the number of hidden units in the LSTM.Gate r tells you how relevant is c to computing the next candidate for c. Long Short Term Memory(LSTM) UnitDifference between LSTM and GRU(LSTM comes earlier, and GRU can be regarded as a special case of LSTM). Forget GateFor the sake of this illustration, lets assume we are reading words in a piece of text, and want use an LSTM to keep track of grammatical structures, such as whether the subject is singular or plural. If the subject changes from a singular word to a plural word, we need to find a way to get rid of our previously stored memory value of the singular/plural state. In an LSTM, the forget gate lets us do this: \Gamma_f^{\langle t \rangle} = \sigma(W_f[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_f)\tag{1}Here, W_f are weights that govern the forget gate’s behavior. We concatenate [a^{⟨t−1⟩},x^{⟨t⟩}] and multiply by W_f. The equation above results in a vector \Gamma_f^{\langle t \rangle} with values between 0 and 1. This forget gate vector will be multiplied element-wise by the previous cell state c^{\langle t-1 \rangle}. So if one of the values of \Gamma_f^{\langle t \rangle} is 0 (or close to 0) then it means that the LSTM should remove that piece of information (e.g. the singular subject) in the corresponding component of c^{\langle t-1 \rangle}. If one of the values is 1, then it will keep the information. Update GateOnce we forget that the subject being discussed is singular, we need to find a way to update it to reflect that the new subject is now plural. Here is the formulate for the update gate: \Gamma_u^{\langle t \rangle} = \sigma(W_u[a^{\langle t-1 \rangle}, x^{\{t\}}] + b_u)\tag{2}Similar to the forget gate, here \Gamma_u^{\langle t \rangle} is again a vector of values between 0 and 1. This will be multiplied element-wise with $\tilde{c}^{\langle t \rangle} $, in order to compute c^{\langle t \rangle}. Updating the cellTo update the new subject we need to create a new vector of numbers that we can add to our previous cell state. The equation we use is: \tilde{c}^{\langle t \rangle} = \tanh(W_c[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_c)\tag{3}Finally, the new cell state is: c^{\langle t \rangle} = \Gamma_f^{\langle t \rangle}* c^{\langle t-1 \rangle} + \Gamma_u^{\langle t \rangle} *\tilde{c}^{\langle t \rangle} \tag{4}Output gateTo decide which outputs we will use, we will use the following two formulas: \Gamma_o^{\langle t \rangle}= \sigma(W_o[a^{\langle t-1 \rangle}, x^{\langle t \rangle}] + b_o)\tag{5}a^{\langle t \rangle} = \Gamma_o^{\langle t \rangle}* \tanh(c^{\langle t \rangle})\tag{6}Where in equation 5 you decide what to output using a sigmoid function and in equation 6 you multiply that by the tanh of the previous state. Bidirectional RNN(BRNN)Week Two - Natural Language Processing &amp; Word EmbeddingsTransfer learning and word embeddings1.Learn word embeddings from large text corpus. (1-100B words)(Or download pre-trained embedding online.)2.Transfer embedding to new task with smaller training set. (say, 100k words)3.Optional: Continue to finetune the word embeddings with new data. Computation of Similarities:Cosine similarity: sim(u,v)=\frac{u^Tv}{||u||_2||v||_2}Euclidean distance: ||u-v||^2 Embedding matrixThe embedding matrix is denoted as E.The embedding for word j can be calculated as e_j=E\cdot o_j.Here, e means embedding and o means one-hot. And in practice, we just use specialized function to look up an embedding rather than use costly matrix multiplication. Context/target pairsContext:· Last 4 words· 4 words on left &amp; right· Last 1 word· Nearby 1 word Word2VecUsing skip-grams: o_c\to E\to e_c\to o\to \hat{y}Softmax:p(t|c)=\frac{e^{\theta_tT_{e_c}}}{\sum_{j=1}^{10000}e^{\theta^T_je_c}}\mathscr{L}(\hat y,y)=-\sum_{i=1}^{10000}y_i\log\hat{y_i}Here, e_c=E\cdot o_c and \theta_t is the parameter associated with output t. Problems:The cost of computation p(t|c)=\frac{e^{\theta_tT_{e_c}}}{\sum_{j=1}^{10000}e^{\theta^T_je_c}} is too high.Solution:Using hierarchal softmax. Negative samplingRandomly choose k+1 examples, where only 1 example is positive and the remaining k are negative. (The value of k is dependent on the size of data sets. If the dataset is big, k = 2-5; if the dataset is small, k = 5-20).Instead of using softmax, compute k times binary classification to reduce the computation. GloVe word vectors-x_{ij}: the number of times i appears in context of j. Thus, x_{ij}=x_{ji} minimize\sum_{i=1}^{10000}\sum_{j=1}^{10000}f(X_{ij})(\theta_i^Te_j+b_i-b_j'-\log{X_{ij}})^2Applications using Word EmbeddingsSentiment Classification and Debiasing. Week ThreeMachine translation can be regarded as a conditional language model.The original language model compute the probability P(y^{},...,y^{}),while the machine translation computes the probability P(y^{},...,y^{}|x^{},...,x^{}). Therefore, it can be regarded as conditional language model.The machine translation contains two parts: encoder and decoder. Just find the most likely translation. \arg \max P(y^{},...,y^{}|x)(not use greedy search) Beam SearchPick a hyperparameter B. In each layer of RNN, pick B most possible output.Since the probability can be computed as: P(y^{},...,y^{}|x)=P(y^{}|x)\times P(y^{}|x,y^{})\times...\times P(y^{}|x,y^{},...,y^{})(Beam search with B=1 is greedy search.) Length normalization \arg\max\prod_{t=1}^{T_y}P(y^{}|x,y^{},...,y^{})The range of possibilities is [0,1]. Therefore the original formula can be extremely small with many small values’ multiplication. To avoid such situations, use log in calculations: \arg\max\sum_{t=1}^{T_y}\log P(y^{}|x,y^{},...,y^{})Machine tends to make short translation to maximize the result, while a too short translation is not satisfying. Therefore, add another hyperparameter to counteract such problem: \frac{1}{T_y^\alpha}\sum_{t=1}^{T_y}\log P(y^{}|x,y^{},...,y^{})Unlike exact search algorithms like BFS or DFS, Beam Search runs faster but is not guaranteed to find exact maximum for arg max P(y|x). Error analysisThere’re two main models in machine translation: RNN part and Beam Search part. If the training error is high, we want to figure out which part is not functioning well.Use (y^*} to represent human’s translation and (\hat y) as machine’s. Case 1: P(y^*|x)>P(\hat y|x)Beam search chose \hat y. But y^* attains higher P(y|x).Conclusion: Beam search is at fault. Case 2: P(y^*|x)\le P(\hat y|x)In fact, y^* is a better translation than \hat y. But RNN predicted P(y^*|x)\le P(\hat y|x)Conclusion: RNN model is at fault. Bleu scorep_1=\frac{\sum_{unigram\in y}count_{clip}(unigram)}{\sum_{unigram\in\hat y}count(unigram)}p_n=\frac{\sum_{ngram\in y}count_{clip}(ngram)}{\sum_{ngram\in\hat y}count(ngram)}Here, p_n= Bleu score on n-grams only.Combined Bleu score: BP\cdot \exp(\frac{1}{4}\sum_{n=1}^4p_n)BP is brevity penalty with BP=\begin{cases}1&\text{if MT_output_length>reference_output_length}\\\text{exp(1-MT_output_length/reference_output_length)} &\text{otherwise}\end{cases}Attention model a^{})}{\sum_{t'=1}^{T_x}\exp(e^{}= amount of attention y^{} should pay to a^{}=(\overrightarrow a^{})\sum_{t'}\alpha^{]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>learning note</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Learning]]></title>
    <url>%2F2018%2F02%2F07%2Fpython-learning%2F</url>
    <content type="text"><![CDATA[ForewordWhatLearning Python by myself. Here’s some environment configuration:Version: Python 3.6.3Platform: macOS 10.12.6Interpreter: terminalText editor: Sublime Text 3 Why Self interest Courses Prerequisites: CS229, Deep Learning, etc (Perhaps next semester I have the chance to teach freshman something about Python:D) HowMaterial: The Python Tutorial: Official documentation Python Numpty Tutorial: Quick introduction to Python and Numpy provided by Stanford Python教程: Chinese Python tutorial CodeStepByStep: Code practice online Python 3.6.4 documentation These materials should be enough. What I use is the official tutorial to get an detailed understanding of Python and Python’s most noteworthy features, and get a good idea of the language’s flavor and style. WhenI plan to get the hang of Python in my winter vacation.Try to get more familiar with Python with practical applications. BasicsInteractive Mode &amp; Executable modeWhen commands are read from a tty, the interpreter is said to be in interactive mode. To start interactive mode, type Python3 in terminal(the default Python version of macOS is Python2, so type Python would start Python2). To stop interactive mode, type exit() to quit. If code is saved as file with .py, then type Python3 filename.py in terminal to compile and run the file. On BSD’ish Unix systems, Python scripts can be made directly executable, like shell scripts, by putting the line #!/usr/bin/env python3.The script can be given an executable mode, or permission, using the chmod +x script.py command.On Windows systems, there is no notion of an “executable mode”. The Python installer automatically associates .py files with python.exe so that a double-click on a Python file will run it as a script. The extension can also be pyw, in that case, the console window that normally appears is suppressed. Comment &amp; PromptCommentComments in Python start with the hash character, #, and extend to the end of the physical line.The # sign will only comment out a single line, if it’s necessary to add multi-line comments, just begin with # each line. (For multi-line comments, include the whole block in a set of triple quotation marks is okay in .py file, but not interactive mode.) 12# This is a comment.# Here's another PromptWhen commands are read from a tty, the interpreter is said to be in interactive mode. In this mode it prompts for the next command with the primary prompt, usually three greater-than signs (&gt;&gt;&gt;); for continuation lines it prompts with the secondary prompt, by default three dots (...).Generally the prompts are primary prompt. Secondary prompts are used in control flow like if, while, etc.Primary prompt (after python3 command in my terminal): 12345$ python3Python 3.6.3 (default, Oct 28 2017, 21:24:10) [GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)] on darwinType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; Secondary prompt (example from tutorial): 12345&gt;&gt;&gt; the_world_is_flat = True&gt;&gt;&gt; if the_world_is_flat:... print("Be careful not to fall off!")...Be careful not to fall off! Input and OutputWell, this part is not introduced in tutorial, but when dealing with online practice(like CodeStepByStep), it’s necessary to know how to input and output. So I’d include some information here. Input:1It&apos;s advisable to add some prompts when asking for input, so we can add string parameters when calling `input` function. ```x = input(&quot;prompts&quot;) The default type of x is string. If we input an integer and what to use x as an integer, use type conversion with int(). x = int(input(&quot;prompts&quot;)) Output:Just like MATLAB, we can output a variable’s value by typing the variable’s name, or use the print() function.When concatenating strings in print(), we can use both , and +. When using ,, we don’t need to convert int/float to string, and every , is treated as a blank space; while we need to convert int/float to string using str() when using +, but + won’t add extra blank space.printf-style Coding Style Use 4-space indentation, and no tabs. Wrap lines so that they don’t exceed 79 characters. Use blank lines to separate functions and classes, and larger blocks of code inside functions. When possible, put comments on a line of their own. Use docstrings. Use spaces around operators and after commas, but not directly inside bracketing constructs: a = f(1, 2) + g(3, 4) Name your classes and functions consistently; the convention is to CamelCase for classes and lower_case_with_underscores for functions and methods. Always use self as the name for the first method argument. Don’t use fancy encodings if your code is meant to be used in international environments. Python’s default, UTF-8, or even plain ASCII work best in any case. Likewise, don’t use non-ASCII characters in identifiers if there is only the slightest chance people speaking a different language will read or maintain the code. NumberPython interpreter can act as a simple calculator. So just type math expressions will get the calculation result. Data typeintfloat DecimalFraction Complex numbers: use j or J suffix to indicate the imaginary part(e.g. 3+5j). Operation+: Addition. 2 + 2 = 4-: Subtract. 3 - 1 = 2*: Multiply. 2 * 2 = 4**: Power. 2 ** 7 = 128/: Division. Always returns a float. 10 / 3 = 3.3333333333333335//: Floor division. Discard any fractional result and get an integer result. _: Last printed expression(easier to continue calculations). ConditionsComparison&lt; less than, &gt; greater than, == equal to, &lt;= less than or equal to, &gt;= greater than, != not equal toin and not in check whether a value occurs (does not occur) in a sequence.is and is not compare whether two objects are really the same object; this only matters for mutable objects like lists. Booleanand, or, notTrue, False.Any non-zero integer value is true; zero is false. The condition may also be any sequence(string, list, etc): anything with a non-zero length is true, empty sequences are false.short-circuit. StringsStrings in Python can be enclosed in both single quotes and double quotes. Escape characterJust like C, \ can be used to escape quotes in Python as well. \t,\n,etc. Use raw strings by adding an r before the first quote can prevent \ from being treated as special characters. 12&gt;&gt;&gt; print(r'C:\some\name')C:\some\name ConcatenatingStrings can be concatenated with + operator, and repeated with *.For string literals(i.e. the ones enclosed between quotes) next to each other are automatically concatenated. IndexIndices of strings can be non-negative(just like C array) and negative(start counting from the right). 12345 +---+---+---+---+---+---+ | P | y | t | h | o | n | +---+---+---+---+---+---+ 0 1 2 3 4 5 6-6 -5 -4 -3 -2 -1 SlicingLike MATLAB, Python supports slicing(word[0:2]), which allows to obtain substring.Note the start is always included, and the end always excluded.Default: an omitted first index defaults to zero, an omitted second index defaults to the size of the string being sliced. Attempting to use an index that is too large will result in an error. However, out of range slice indexes are handled gracefully when used for slicing. ImmutablePython strings are immutable, just as in Java. Thus, if it’s necessary to edit a string, just create a new one. OthersThe built-in function len() returns the length of a string.String Methods Control Flowif Statement 123456if ... : ...elif ... : ...else: ... There can be zero or more elif parts, and the else part is optional.Note there’s no switch case in Python. for StatementPython’s for statement iterates over the items of any sequence(a list or a string), in the order that they appear in the sequence. 12345678&gt;&gt;&gt; # Measure some strings:... words = ['cat', 'window', 'defenestrate']&gt;&gt;&gt; for w in words:... print(w, len(w))... cat 3window 6defenestrate 12 The range() Functionfor i in range(5)range() function may contain 1, 2 or 3 parameters.range(term): Generate term values from 0 to (term - 1). Note that term should be positive integers or it will return an empty list.range(begin, end): Generate values from begin to (end - 1).range(begin, end, step): Specify a different increment(step), which can even be negative. In many ways the object returned by range() behaves as if it is a list, but in fact it isn’t. It is an object which returns the successive items of the desired sequence when you iterate over it, but it doesn’t really make the list, thus saving space.We say such an object is iterable, that is, suitable as a target for functions and constructs that expect something from which they can obtain successive items until the supply is exhausted. break and continue Statements, and else Clauses on Loops The break statement breaks out of the innermost enclosing for or while loop.The continue statement continues with the next iteration of the loop.These two statements are borrowed from C. Loop statements may have an else clause; it is executed when the loop terminates through exhaustion of the list (with for) or when the condition becomes false (with while), but not when the loop is terminated by a break statement. 1234567891011121314151617&gt;&gt;&gt; for n in range(2, 10):... for x in range(2, n):... if n % x == 0:... print(n, 'equals', x, '*', n//x)... break... else:... # loop fell through without finding a factor... print(n, 'is a prime number')...2 is a prime number3 is a prime number4 equals 2 * 25 is a prime number6 equals 2 * 37 is a prime number8 equals 2 * 49 equals 3 * 3 pass StatementsThe pass statement does nothing. It can be used when a statement is required syntactically but the program requires no action. 123&gt;&gt;&gt; while True:... pass # Busy-wait for keyboard interrupt (⌃+C)... This is commonly used for creating minimal classes: 123&gt;&gt;&gt; class MyEmptyClass:... pass... pass can be used as a place-holder for a function or conditional body when you are working on new code, allowing you to keep thinking at a more abstract level. 123&gt;&gt;&gt; def initlog(*args):... pass # Remember to implement this!... FunctionsDetailThe keyword def introduces a function definition. It must be followed by the function name and the parenthesized list of formal parameters. The statements that form the body of the function start at the next line, and must be indented. docstringThe first statement of the function body can optionally be a string literal(in three single quotes &#39;&#39;&#39; &#39;&#39;&#39;); this string literal is the function’s documentation string, or docstring. This line should begin with a capital letter and end with a period. call by valueThe actual parameters (arguments) to a function call are introduced in the local symbol table of the called function when it is called; thus, arguments are passed using call by value (where the value is always an object reference, not the value of the object). When a function calls another function, a new local symbol table is created for that call.Actually, call by object reference would be a better description, since if a mutable object is passed, the caller will see any changes the callee makes to it (items inserted into a list). returnThe return statement returns with a value from a function. return without an expression argument returns None. Falling off the end of a function also returns None. default argument valuesWhen defining functions, it’s useful to specify a default value for one or more arguments. This creates a function that can be called with fewer arguments than it is defined to allow.Remember that the default value is evaluated only once. keyword argument &amp; positional argumentFrom GlossaryA value passed to a function(or method) when calling the function. There are two kinds of argument:· keyword argument. an argument preceded by an identifier(e.g. name=) in a function call or passed as a value in a dictionary preceded by **.· positional argument. an argument that is not a keyword argument. Positional arguments can appear at the beginning of an argument list and/or be passed as elements of an iterable preceded by *. When a final formal parameter of the form **name is present, it receives a dictionary containing all keyword arguments except for those corresponding to a formal parameter. This may be combined with a formal parameter of the form *name (described in the next subsection) which receives a tuple containing the positional arguments beyond the formal parameter list. (*name must occur before **name.) Data StructuresSequence Types - list, tuple, rangeSet Types - set, frozensetMapping Types - dict ListsList can be written as a list of comma-separated values (items) between square brackets. (similar to Java’s ArrayList)Lists might contain items of different types, but usually the items all have the same type. square = [1, 4, 9, 16, 25] Index and slicing are similar to those of String. MutableLists are a mutable type, i.e. it is possible to change their content. Concatenation+ operator: squares + [36, 49]append method: squares.append(64) Methods of list objectslist.append(x)Add an item to the end of the list. Equivalent to a[len(a):] = [x]. list.extend(iterable)Extend the list by appending all the items from the iterable. Equivalent to a[len(a):] = iterable. list.insert(i,x)Insert an item at a given position. The first argument is the index of the element before which to insert, so a.insert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x) list.remove(x)Remove the first item from the list whose value is x. It is an error if there is no such item. list.pop([i])Remove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and returns the last item in the list. list.index(x[, start[, end]])Return zero-based index in the list of the first item whose value is x. Raises a ValueError if there is no such item.The optional arguments start and end are interpreted as in the slice notation and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument. list.count(x)Return the number of times x appears in the list. list.sort()Sort the items of the list in place. list.reverse()Reverse the elements of the list in place. list.copy()Return a shallow copy of the list. Equivalent to a[:]. List ComprehensionsList comprehensions provide a concise way to create lists.A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for of if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if clauses which follow it.E.g: 123456&gt;&gt;&gt; squares = []&gt;&gt;&gt; for x in range(10):... squares.append(x**2)...&gt;&gt;&gt; squares[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] It is equivalent to squares = [x**2 for x in range(10)] TuplesA tuple consists of a number of values separated by commas. Comparison with list Type tuple list Immutable immutable mutable Element heterogeneous homogeneous Access unpacking/indexing iterating Packing and UnpackingPackingt = 12345, 54321, &#39;hello!&#39; is an example of tuple packing Unpackingx, y, z = t is called sequence unpacking and works for any sequence on the right-hand side. Sequence unpacking requires that there are as many variables on the left side of the equals sign as there are elements in the sequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking. SetsA set is an unordered collection with no duplicate elements.Curly braces {} or the set() function can be used to create sets.set() can be used to remove duplicated items in the list. DictionariesDictionaries are index by keys, which can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. Since lists are mutable, lists can’t be used as keys as well. d = {key: value, ...}: a pair of braces creates an empty dictionary. Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary. Also can use dict() constructor.list(d.keys()): return a list of all the keys used in the dictionary in arbitrary order.sorted(d.keys()): return the sorted list of keysin: check whether a single key is in the dictionary When looping through dictionaries, the key and corresponding value can be retrieved at the same time using the items() method. 123456&gt;&gt;&gt; knights = &#123;'gallahad': 'the pure', 'robin': 'the brave'&#125;&gt;&gt;&gt; for k, v in knights.items():... print(k, v)...gallahad the purerobin the brave ModulesA module is a file containing Python definitions and statements. The file name is the module name with the suffix .py appended. Definitions from a module can be imported into other modules or into the main module (the collection of variables that you have access to in a script executed at the top level and in calculator mode). Within a module, the module’s name (as a string) is available as the value of the global variable __name__. Some tipsThe keyword argument end can be used to avoid the newline after the output, or end the output with a different string. 123456&gt;&gt;&gt; a, b = 0, 1&gt;&gt;&gt; while b &lt; 1000:... print(b, end=',')... a, b = b, a+b...1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987, in keyword tests whether or not a sequence contains a certain value. The square brackets in the method signature denote that the parameter is optional, not that you should type square brackets at that position. This is frequent in the Python Library Reference. When looping through a sequence, the position index and corresponding value can be retrieved at the same time using the enumerate() function. 123456&gt;&gt;&gt; for i, v in enumerate(['tic', 'tac', 'toe']):... print(i, v)...0 tic1 tac2 toe To loop over two or more sequence at the same time, the entries can be paired with the zip() function. 12345678&gt;&gt;&gt; questions = [&apos;name&apos;, &apos;quest&apos;, &apos;favorite color&apos;]&gt;&gt;&gt; answers = [&apos;lancelot&apos;, &apos;the holy grail&apos;, &apos;blue&apos;]&gt;&gt;&gt; for q, a in zip(questions, answers):... print(&apos;What is your &#123;0&#125;? It is &#123;1&#125;.&apos;.format(q, a))...What is your name? It is lancelot.What is your quest? It is the holy grail.What is your favorite color? It is blue. Something to be detailedHere stores something that is introduced in tutorial briefly, waiting to be discussed in detail in the future. Question 1234567total = 0while True: number = int(input(&quot;Type a number: &quot;)) if number == -1: print (&quot;Sum is&quot;, total) break total += number The above code is correct, while the following is buggy with IndentationError: unexpected indent 1234567total = 0while True: number = int(input&apos;Type a number: &apos;) if number == -1: break total += numberprint(&apos;Sum is&apos;, total) I don’t know why Arbitrary Argument Lists and Unpacking Argument ListsIntroduced in Section 4.7, MethodA method is a function that ‘belongs’ to an object and is named obj.methodname, where obj is some object (this may be an expression), and methodname is the name of a method that is defined by the object’s type. Different types define different methods. Methods of different types may have the same name without causing ambiguity. Lambda ExpressionsSmall anonymous functions can be created with the lambda keyword. This function returns the sum of its two arguments: lambda a, b: a+b. Lambda functions can be used wherever function objects are required. They are syntactically restricted to a single expression. Semantically, they are just syntactic sugar for a normal function definition. Like nested function definitions, lambda functions can reference variables from the containing scope: 12345678&gt;&gt;&gt; def make_incrementor(n):... return lambda x: x + n...&gt;&gt;&gt; f = make_incrementor(42)&gt;&gt;&gt; f(0)42&gt;&gt;&gt; f(1)43 list.sort(key=None, reverse=False)The arguments can be used for sort customization, see sorted(). The del statementRemove an item from a list given its index instead of its value. The del statement can also be used to remove slices from a list or clear the entire list. 12345678910&gt;&gt;&gt; a = [-1, 1, 66.25, 333, 333, 1234.5]&gt;&gt;&gt; del a[0]&gt;&gt;&gt; a[1, 66.25, 333, 333, 1234.5]&gt;&gt;&gt; del a[2:4]&gt;&gt;&gt; a[1, 66.25, 1234.5]&gt;&gt;&gt; del a[:]&gt;&gt;&gt; a[] del can also be used to delete entire variables.del can delete a key:value pair in dict, the parameter is just dict’s key.]]></content>
      <tags>
        <tag>learning note</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见2017 你好2018]]></title>
    <url>%2F2018%2F01%2F01%2Fhello-2018%2F</url>
    <content type="text"><![CDATA[窗外的跨年狂欢夜开始全场倒计时，室内的手机屏幕上的显示时间却调皮地率先变成了00:00。新的一天。新的一月。以及 新的一年。回首2017，有很多人生的第一次呢。第一次知乎回答收到赞感谢收藏，第一次写专栏文章，搭建了自己的博客并发表了第一篇文章，第一次加入实验室，第一次阅读英文论文，第一次完成Coursera的课程……其实也都蛮微不足道的，不过万事开头难啦。既然踏出了勇敢的第一步，那就坚持大步走下去吧。纵使路途荆棘遍布，亦会有鲜花相随。为了申请美国的研究生，下个学期将会无比繁忙。TOEFL、GRE、补CS的相关课程、重修数学课……此外还要考虑实习、科研、交流等事项，可以说是很辛苦呢。不过这都是带有明确的目的指向，而不似大一大二的漫无目的。希望自己能在2018好好努力，争取收到各种好消息叭。年底时莫名冒出了“佛系”的说法，意指无欲无求，一切随缘。感觉自己在生活方面很早就进入了该种状态吧。虽然在玉泉属于最年轻的一批人，不过莫名地感觉过上了玉泉的老人生活。不波不澜，似直流信号，偶尔的脉冲信号荡起一丝起伏。2017年也发生了许多大事。中国的互联网是健忘的，不过，历史不能遗忘。此不言，仅铭记。你好2018，请多指教~]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bitcoin-and-cryptocurrencies]]></title>
    <url>%2F2017%2F12%2F28%2Fbitcoin-and-cryptocurrencies%2F</url>
    <content type="text"><![CDATA[Week One - Introduction to Crypto and CryptocurrenciesHash functionTakes any string as inputfixed-size output (e.g. 256bits just as BitCoin)efficiently computable Security properties:Collision-freeNobody can find x and y such that x!=y and H(x)=H(y). Note: Collisions do exist. The possible outputs are finite(string of 256 bits in size), while the possible inputs can be a string of any size. To find a collision of any hash function: Trying 2^{130} randomly chosen inputs and chances are 99.8% that two of them will collide. Well, it takes too long to matter.For some possible H’s, there’s a faster way to find collisions; for others, we haven’t known yet.No H has been proven collision-free. Hiding(r|x) means that take all the bits of r and put after them all the bits of x.If r is chosen from a probability distribution that has high min-entropy, then given H(r|x), it is infeasible to find x.High min-entropy means that the distribution is “very spread out”, so that no particular value is chosen with more than negligible probability. Puzzle-friendlyFor every possible output value y, if k is chosen from a distribution with high min-entropy, then it is infeasible to find x such that H(k|x)=y. ApplicationsHash as message digest.If we know H(x)=H(y), it’s safe to assume that x=y.To recognize a file that we saw before, just remember its hash.It’s useful because the hash is small, while a file may be very big. CommitmentWant to “seal a value in an envelope”, and “open the envelope” later.Commit to a value, reveal it later.12(com, key) := commit(msg)match := verify(com, key, msg) To seal msg in envelope: (com, key) := commit(msg) — then publish comTo open envelope: publish key, msg anyone can use verify() to check validity Commitment API:commit(msg):=(H(key|msg),key) , where key is a random 256-bit valueverify(com, key, msg):=(H(key|msg)==com) Security properties:Hiding: Given com, infeasible to find msg.Binding: Infeasible to find msg != msg&#39; such that verify(commit(msg), msg&#39;) == true. Search PuzzleGiven a “puzzle ID” id (from high min-entropy distribution) and a target set Y,try to find a “solution” x such that H(id|x)∈Y.Puzzle-friendly property implies that no solving strategy is much better than trying random values of x. SHA256SHA-256 takes the message that you’re hashing, and it breaks the message up into blocks that are 512 bits in size(add some padding at the end 100…00).IV: 256 bit value(look up in a standards document).c: the compression function. Take 768 bits(256+512) and run through this function and out comes 256 bits. Hash PointerHash pointer is pointer to where some info is stored, and (cryptographic) hash of the info.If we have a hash pointer, we can ask to get the info back, and verify that it hasn’t changed. Data structure of blockchain:This is blockchain, and it’s similar to linked list.If some adversary wants to change a block’s data(e.g., the left one), then the content of that block is changed. And the middle block’s hash pointer is not consistent to the left block any more. So the adversary has to change middle block’s header, and next block’s header and so on. Merkle treeAdvantages of Merkle trees:Tree holds many items, but just need to remember the root hash.Can verify membership in O(log n) time/space. Digital SignatureWhat we want from signatures is two things: Only you can make your signature, but anyone who sees your signature can verify that it’s valid. Signature is tied to a particular document, because signature is not just a signature, it signifies your agreement or endorsement of a particular document. API for digital signatures123(sk,pk):=generateKeys(keySize)sig:=sign(sk, message)isValid:=verify(pk, message, sig) Requirements for signatures·Valid signatures verifyverify(pk, message, sign(sk, message))==true·Can’t forge signaturesAn adversary who knows your public key and gets to see signatures on some other messages, can’t forge your signature on some message that he wants to forge it on. Practical stuffalgorithms are randomized need good source of randomnesslimit on message size fix: use Hash(message) rather than messagefun trick: sign a hash pointer signature “covers” the whole structure Simple CryptocurrenciesGoofyCoinGoofy can create new coins. A coin’s owner can spend it. The recipient can pass on the coin again. Problem: Double-spending attackthe main design challenge in digital currency ScroogeCoin CreateCoin transaction creates new coins. PayCoin transaction consumes (and destroys) some coins, and create new coins of the same total value.Valid if:-consumed coins valid-not already consumed-total value out = total value in-signed by owners of all consumed coins Note: Coins are immutable, that is, coins can’t be transferred, subdivided, or combined. Week Two - How Bitcoin Achieves DecentralizationWhy consensus protocols?Traditional motivation: reliability in distributed systemsDistributed key-value store enables various applications: DNS, public key directory, stock trades … Distributed consensusThe protocol terminates and all correct nodes decide on the same valueThis value must have been proposed by some correct node Why consensus is hard?Nodes may crashNodes may be maliciousNetwork is imperfect (Not all pairs of nodes connected; faults in network; latency) Consensus algorithm (simplified) New transactions are broadcast to all nodes Each node collects new transactions into a block In each round a random node gets to broadcast its block Other nodes accept the block only if all transactions in it are valiid (unspent, valid signatures) Nodes express their acceptance of the block by including its hash in the next block they create What can a malicious node do? - Double SpendingHonest nodes will extend the longest valid branch. In the above image, the green block and the red block are identical. So chances are that the next node will extend the red block, and so on, which makes the double-spending attack. However, from Bob’s view, it looks like this:Double-spend attack only occurs with 1 confirmations. If Bob is patient enough and wait for some other confirmations, he’s not likely to suffer double-spend.Double-spend probability decreases exponentially with number of confirmations.(Most common heuristic: 6 confirmations) Incentives and Proof of WorkIncentive 1: block rewardCreator of block gets to include special coin-creation transaction in the block choose recipient address of this transaction Note block creator gets to “collect” the reward only if the block ends up on long-term consensus branch. Incentive 2: transaction feesCreator of transaction can choose to make output value less than input valueRemainder is a transaction fee and goes to block creatorPurely voluntary, like a tip. PoW property1: difficult to computeOnly some nods bother to compute - miners 2: parameterizable costNodes automatically re-calculate the target every two weeks.Goal: average time between blocks = 10 minutes Prob(Alice\ wins\ next\ block)=fraction\ of\ global\ hash\ power\ she\ controls3: trivial to verifyNonce must be published as part of blockOther miners simply verify that H(nonce||prev_hash||tx||...||tx)]]></content>
      <tags>
        <tag>learning note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Digital Image Processing Learning Note]]></title>
    <url>%2F2017%2F12%2F06%2FDIP-learning%2F</url>
    <content type="text"><![CDATA[Recently to accomplish the final assignment of Digital Signal Processing Experiment, we decide to do something about digital image processing using MATLAB and LabView. And the reference book is Digital Image Processing Using MATLAB Second Edition by Rafael C. Gonzalez et al. Here I’d like to keep the notes, mainly the functions that’s useful. Intensity Transformation Functionsimadjust: adjust image intensityg = imadjust(f, [0 1], [1 0]); shows the negative image, which is same as the function g = imcomplement(f)Parameter gamma specifies the shape of the curve that maps the intensity values in f to create g. If gamma is less than 1, the mapping is weighted toward higher(brighter) output values. If gamma is greater than 1, the mapping is weighted toward lower(darker) output values.]]></content>
      <tags>
        <tag>learning note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MATLAB整理]]></title>
    <url>%2F2017%2F11%2F18%2Fmatlab-summary%2F</url>
    <content type="text"><![CDATA[以前一直不是很喜欢MATLAB。（数据都是矩阵化，运算还必须保持矩阵维度的一致；非类C的语法格式；在不喜欢的实验课上使用……）不过随着学习的深入，发现MATLAB真的很强大很实用：这个学期的数字信号处理、大作业要用到的数字图像处理、电子商务系统中Item-based CF算法的数据分析、Coursera上的机器学习，这些课程都用到了MATLAB，再加上浙大十月份刚刚购入了MATLAB的正版许可证，种种因素下感觉竟然对MATLAB有了一点点喜爱。不过MATLAB毕竟还是蛮复杂的，虽然在Machine Learning Note中有记录部分笔记，不过还是专门开篇文章来记录一下w也希望对看到这篇文章的你有所帮助~ 基础MATLAB语言与C语言的不同大部分同学应该在接触MATLAB之前都接触过类C语言（C、C++、Java），而MATLAB作为一门解释型语言，与类C语言相比还是有比较大的不同。所以一开始想简单地列举一下MATLAB语言(下简称m语言)和类C语言（下简称C语言）的不同。变量定义C语言要求变量先定义后使用，如int i，double sum。而m语言中并不需要定义变量这一步，只要在赋值语句的左边出现的变量都可以直接使用（不要在赋值语句的右边使用未出现过的变量名即可）。数值运算C语言中的数值运算一般情况下比较符合日常生活中的数值运算，最多也就出现10/3=3这种个别的反直觉的结果。而m语言中的数值都是矩阵化的，在运算方面都是需要根据矩阵运算法则进行。（例如加法需要两个矩阵维数相等，乘法就需要第一个矩阵的列=第二个矩阵的行,etc）。此外m语言还有一种element-wise（按元素）的运算，即.*、.^等。如A=[a1,a2,a3];，B=[b1,b2,b3];，根据线代知识这两个矩阵无法进行矩阵相乘(*)运算，但可以进行按元素乘(.*)运算，运算结果A.*B=[a1b1,a2b2,a3b3]。程序运行C语言是编译型语言，需要将后缀名为.c的文件通过编译后方能运行。而m语言是解释型语言，直接一句一句就可以执行语句。所以MATLAB可以在命令行窗口输入指令后直接执行得到结果，也可以保存为.m文件后再执行该.m文件。 MATLAB桌面版简介这是MATLAB R2017b版本的截图，其中用不同颜色划分了不同的区域。功能区提供打开文件、保存、设置断点等诸多功能。（因为我都没用过功能区……要么快捷键要么输指令，所以不详细介绍功能区了）就说几个有用的快捷键：Ctrl+N(MacBook用Command键替换Ctrl键，下同)：新建.m文件Ctrl+O：打开文件（一般是打开.m文件）Ctrl+S：保存文件 当前路径文件显示当前路径下的所有文件/文件夹，不同格式的文件会有不同的图标。例如图中的ex3_nn.m和ex3.m为可执行m文件，可以在命令行窗口中直接输入文件名（ex3_nn、ex3）便可以执行该文件；displayData.m、fmincg.m等为函数文件，定义了不同功能的函数（由于函数往往需要调用参数，所以不建议直接执行函数文件）；ex3data1.mat、ex3weights.mat等为数据文件，MATLAB可以直接读取数据文件中的数据。 编辑器新建/打开.m文件，或者对.m文件进行编辑时，会有编辑器窗口（默认情况下命令行窗口会占据编辑器的位置。虽然与其他的编辑器，例如Sublime Text、VS Code等相比，MATLAB编辑器略显不足，只有少量的代码高亮，以及中文字体可能出现乱码情况（直接复制代码到Word中会出现乱码，需选择性粘贴-带格式文本；其他文本编辑器打开.m文件也会出现乱码），不过毕竟是自带的编辑器，也将就着使用叭~（另：MATLAB还有实时脚本live script功能，后缀名为.mlx，可以包含函数图像，在写论文等情况下建议使用，一般情况下就直接用.m文件即可。） 命令行窗口命令行窗口中可以执行多种操作。如上文提到的输入.m程序名直接执行程序（注意只需要输入文件名即可，不需要输入.m后缀），还可以复制.m程序中的部分语句到命令行中进行执行，后文还会提到功能各异的各种指令。 工作区工作区里会显示当前程序下所有变量的值/维度，便于进行调试。 基本指令帮助函数helphelp可以说是MATLAB最有用的指令了。不清楚某个函数的使用方法，直接在命令行窗口中输入help 函数名便可以查看函数使用及相关示例，例如help plot。甚至还可以用help help来查看如何使用help函数。所以最先介绍一下help函数~ dochelp指令是简单地了解指令，而doc指令则是更完整地查看MATLAB的相关文档。 简单赋值纯量a=5;MATLAB中所有的变量都是数组(array)，或者说矩阵(matrix)。单独的一个数字，在MATLAB中也叫做scalar（纯量），是一个特殊的1×1的矩阵。另：MATLAB中可以用pi直接表示圆周率π，不过不可以直接使用e表示自然底数（会提示未定义函数或变量’e’），要进行自然底数的运算请使用exp()函数。 矩阵初始化ones()zeros()eyes()上面三函数都可以用于矩阵/向量的初始化。其中ones和zeros的使用方法类似。ones是矩阵元素均为1，zeros是矩阵元素均为0，eyes是生成单位矩阵（即主对角线上的元素均为1，其余均为0。）。ones(N)，zeros(N)，eyes(N)：生成N×N的矩阵；ones(M,N)，zeros(M,N)：生成M×N的矩阵。 随机数rand()：符合均匀分布(0,1)的伪随机数randn()：符合标准正态分布的伪随机数rand()和randn()的使用方法与ones和zeros类似。randi(MAX,N)、randi(MAX,M,N)：符合均匀离散分布1:MAX的伪随机数（即1，2，…，MAX），除多一个参数MAX外，其他与rand和randn使用方法类似。 ,;:When you separate numbers by spaces (or commas), MATLAB combines the numbers into a row vector, which is an array with one row and multiple columns (1-by-n). When you separate them by semicolons, MATLAB creates a column vector (n-by-1)当使用空格或者逗号分隔数字时，MATLAB将这些数字结合成行向量(1×n)；当用分号分隔时，MATLAB建立列向量(n×1)。换言之，在定义矩阵时，,（或者空格）表示同一行间不同元素的分隔，;表示不同行之间的分隔。如[1,2,3;4,5,6]便建立了一个2×3的矩阵 \begin{bmatrix}1&2&3\\4&5&6\end{bmatrix};：分号除了分隔不同行外，还有一种作用是加在一条指令的最后，作用为取消输出结果。如a=1;。这样该指令会执行，不过不会在命令行窗口输出结果。所以建议在编写.m文件时，如无特殊情况每一条语句后都加上;。 :：第一种常见用法是min:max或者min:step:max，前者建立一个[min, min + 1, min + 2, … , max]的矩阵，后者则建立一个[min, min + step, min + 2 step, … , min + n step]。（min + n × step ≤ max, min + (n + 1) × step &gt; max)）如1:2:6的结果为[1,3,5]。（注：linspace(first,last,number_of_elements)是类似于:的一个函数。）第二种用法是表示某一维度的所有元素。如x = A(2,:)即将A矩阵第二行的所有元素赋值给变量x。x = A(1:3,:) 同时使用了:的两种常见用法。该指令将矩阵A的前三行所有元素赋值给变量x。 ...：如果一条语句比较长，则可以使用...后按回车继续写该语句。...表示语句会在下一行继续。一般在参数较多的函数中使用。 矩阵化运算矩阵与向量定义MATLAB通过矩阵化的运算可以有效提高运算速度。MATLAB中的数据都视作矩阵，其中维度为1×n或者n×1的为向量(vector)。size指令可以显示对应矩阵的维度，对于向量则可以使用length指令。 矩阵乘法与按位乘法矩阵乘法的话一般可分为两种：矩阵与纯量的乘法，以及矩阵与矩阵的乘法。这两种乘法都是用运算符*实现。如2 * [1 2 3] = [2 4 6]，以及[1,2;3,4] * [1;1] = [3;7]等。有时两个矩阵的维度相同，可能无法进行矩阵的乘法运算。不过，正如之前介绍的，MATLAB还支持一种按元素运算(element-wise)，运算符为.*。如[1,2,3] .* [2,3,4] = [2,6,12]。 矩阵最大值max(X)：若X为向量，则返回该向量中的最大值；若X为矩阵，则返回一个行向量，每一个元素对应该列的最大值。如max([1,3,5;2,3,4])=[2,3,5]。[m,i]=max(X)：除返回最大值外，还会返回最大值的索引。 矩阵求和sum(x)：列求和sum(x,2)：行求和sum(x(:))：矩阵求和 条件语句for循环一般用法：123for i = 1:n ...end if条件判断：1234if ...elseif ...else ...end switch多重判断：123456switch case 1 ... otherwise ...end 用法与C类似，就是注意一下语法有所不同。 下附四张表格以助理解：(Referring to Digital Image Processing Using MATLAB Second Edition) Arithmetic operators| Operator | Name | Comments and Examples || —- | —- | —- || + | Array and matrix addition | a+b,A+B,or a+A. || - | Array and matrix subtraction | a-b,A-B,A-a,or a-A. || . | Array multiplication | `C=A.B,C(I,J)=A(I,J)B(I,J).` || | Matrix multiplication | A*B,standard matrix multiplication,or a*A,multiplication of a scalar times all elements of A. || ./ | Array right division | C=A./B,C(I,J)=A(I,J)/B(I,J). || .\ | Array left division | C=A.\B,C(I,J)=B(I,J)/A(I,J). || / | Matrix right division | A/B is the preferred way to compute A*inv(B). || \ | Matrix left division | A\B is the preferred way to compute inv(A)*B. || .^ | Array power | If C=A.^B,thenC(I,J)=A(I,J)^B(I,J). || ^ | Matrix power | See help for a discussion of this operator. || .’ | Vector and matrix transpose | A.’,standard vector and matrix transpose. || ‘ | Vector and matrix complex conjugate transpose | A’,standard vector and matrix conjugate transpose.When A is real A.’=A’. || + | Unary plus | +A is the same as 0+A. || - | Unary minus | -A is the same as 0-A or -1*A. || : | Colon | Discussed above. | Relation operators Operator Name &lt; Less than &lt;= Less than or equal to &gt; Greater than &gt;= Greater than or equal to == Equal to ~= Not equal to Logical operators Operator Description &amp; Elementwise AND Elementwise OR ~ Elementwise and scalar NOT &amp;&amp; Scalar AND Scalar OR Flow control statements Statement Description if if,together with else and elseif,executes a group of statements based on a specified logical condition. for Executes a group of statements a fixed(specified) number of times. while Executes a group of statements an indefinite number of times,based on a specified logical condition. break Terminates execution of a for loop or while loop. continue Passes control to the next iteration of a for or while loop,skipping any remaining statements in the body of the loop. switch switch,together with case and otherwise,executes different groups of statements,dependiing on a specified value or string. return Causes execution to return to the invoking function. try catch Changes flow control if an error is detected during execution. 文件操作数据保存载入：save：保存数据为.mat文件load：导入.mat文件中的数据不是很常用，一般可以用鼠标代替操作。：在工作区右键可以执行保存操作，在功能区则可以执行打开操作。 imread：载入常用标准图片格式(GIF, JPEG, PNG, etc).imshow：显示该图片imwrite：将图片保存至当前路径。 datastoreimageDatastore例：ds = imageDatastore(&#39;foo*.png&#39;)：在MATLAB中建立数据储存。参数名为文件夹名或文件名，可以使用通配符*表示多个文件。foo*即表示所有以foo开头的PNG图片。read,readimage,readall. 其他常用指令注释%：百分号后的内容均视为注释内容。类似于类C中的// 清除指令clear：清除工作区变量clc：清除命令行窗口所有指令close all：关闭所有绘图窗口 类Linux指令在命令行窗口中还支持许多Linux常用指令（感兴趣的可以参考我的Linux系统下常用指令）。下面就简单介绍一下： cd ..：返回上层文件夹cd 文件夹1：将路径跳转至当前路径下名为’文件夹1’的文件夹cd ~：将路径跳转至个人主文件夹 mkdir 文件夹1：在当前路径下新建名为’文件夹1’的文件夹rmdir 文件夹1：删除当前路径下名为’文件夹1’的文件夹 Ctrl C：中止当前运行的程序。（注意MacBook下也是Ctrl C） 一般MATLAB中常用的就这些命令啦。 绘图指令https://cn.mathworks.com/help/matlab/ref/linespec.htmlhttps://cn.mathworks.com/help/matlab/ref/chartline-properties.htmlhttps://cn.mathworks.com/help/matlab/creating_plots/using-high-level-plotting-functions.htmlhold ontitlexlabelylabellegend M函数MATLAB的M文件既可以作为直接可执行的MATLAB语句，也可以是函数：接受参数并产生输出。M函数的组成通常有： 函数定义 首行 帮助文本 函数主体 注释 函数定义：function output = name(inputParameter1, inputParameter2...)首行：函数定义后的第一行单行注释。在函数定义与首行之间没有空行。在首行中一般%与第一个单词之间也没有空格，比如%sum Computes the sum...%。使用lookfor指令时显示该行内容。帮助文本：首行后的注释内容。在帮助文本与首行之间也没有空行。使用help指令时会显示首行与帮助文本内容。函数主体：执行计算、赋值等语句的MATLAB代码。注释：除首行与帮助文本外的所有注释。 Deep Learning下面记录一些在MATLAB官方的Deep Learning Onramp课程中使用的函数。alexnet：在MATLAB工作区中建立一个预训练过的深度学习网络”AlexNet”。net = alexnet; classify：对于一个图像进行预测。注：在MATLAB online版本可以直接使用alexnet，不过在桌面版MATLAB中需安装对应支持包，才可以使用AlexNet等预训练过的网络。可以在扩展功能中搜索pretrained network免费下载对应包。 You can use the splitEachLabel function to divide the images in a datastore into two separate datastores.[ds1,ds2] = splitEachLabel(imds,p);The proportion p (a value from 0 to 1) indicates the proportion of images with each label from imds that should be contained in ds1. The remaining files are assigned to ds2.]]></content>
      <tags>
        <tag>tips</tag>
        <tag>MATLAB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Item-Based Collaborative Filtering Recommendation Algorithms reading report]]></title>
    <url>%2F2017%2F11%2F03%2FItem-Based-CFRA-reading-report%2F</url>
    <content type="text"><![CDATA[This semester I’m taking the E-commerce System Structure, and we have come to learn about personalization. In E-commerce, the form of personalization is to recommend items to the user. Recommendation Metrics Prediction accuracy Coverage Novelty Diversity Privacy Scalability Recommendation Strategies Popularity Association role Content based Collaborative filtering Hybrid In the corresponding experiment, our assignment is to read the paper Item-Based Collaborative Filtering Recommendation Algorithms, a famous paper in recommender system. And I’d like to take a note of some key point, with some specific examples and implementation codes. Overview of Collaborative Filtering Based Recommender SystemsFigure 1 shows the schematic diagram of the collaborative filtering process. CF algorithms represent the entire m×n user-item data as a ratings matrix, A. Here ‘m’ is the number of users and ‘n’ is the number of items. Each entry a_{i,j} in A represents the preference score (ratings) of the ith user on the jth item. Each individual ratings is within a numerical scale(e.g., from 1 to 5, the higher the better) and it can as well be 0 or NULL indicating that the user has not yet rated that item.Prediction is a numerical value.Recommendation is a list of N items. The image may be a bit abstract. Here’s my specific example with simplified toy examples. The rating scales from 1 to 5, where 1 indicates ‘dislike the movie very much’, and 5 indicates ‘like the movie very much’. If the rating is blank, then the user has not seen(voted) the movie yet. I’d refer to this table later. Harry Potter Pirates of the Caribbean Titanic Avatar Transformers Alice 3 5 4 1 Bob 3 4 4 1 Carol 4 3 3 1 Dave 4 4 4 3 1 Eve 5 4 5 3 Memory-based and Model-based algorithmsMemory-based CF AlgorithmsMemory-based algorithms utilize the entire user-item database to generate a prediction. These systems employ statistical techniques to find a set of users, known as neighbors, that have a history of agreeing with the target user. The techniques, also known as nearest-neighbor or user-based collaborative filtering, are more popular and widely used in practice. Model-based CF AlgorithmsModel-based collaborative filtering algorithms provide item recommendation by first developing a model of user ratings. Algorithms in this category take a probabilistic approach and envision the collaborative filtering process as computing the expected value of a user prediction, give his/her ratings on other items. Challenges of User-based CF Algorithms Sparsity. Large E-commerce systems like Amazon and Taobao have large item sets, but users can only by a small fraction of the total item set. Scalability. With millions of users and items, a typical web-based recommender system running existing algorithms will suffer serious scalability problems. Item-based Collaborative Filtering AlgorithmThe item-based approach looks into the set of items the target user has rated and computes how similar they are to the target item i and then selects k most similar items. At the same time their corresponding similarities are also computed. Once the most similar items are found, the prediction is then computed by taking a weighted average of the target user’s ratings on these similar items. Item Similarity Computation Cosine-based Similaritysim(i,j)=cos(\vec i,\vec j)=\frac{\vec i\cdot\vec j}{||\vec i||*||\vec j||}Two items are thought of as two vectors in the m dimensional user-space. The similarity between them is measured by computing the cosine of the angle between these two vectors. Take the previous example: Each column can be viewed as a vector. Therefore, the item Harry Potter has a vector of v_{HP}=(0,0,4,4,5) and the item Pirates of the Caribbean has a vector of v_{PC}=(3,3,3,4,4). Note that if the rating is treated as 0 if blank. And the result should be sim(HP,PC)=cos(\vec v_{HP},\vec v_{PC})=\frac{0\cdot 3+0\cdot 3+4\cdot 3+4\cdot 4+5\cdot 4}{\sqrt{4^2+4^2+5^2}\sqrt{3^2+3^2+3^2+4^2+4^2}}=0.83Correlation-based Similaritysim(i,j)=\frac{\sum_{u\in U}(R_{u,i}-\overline R_i)(R_{u,j}-\overline R_j)}{\sqrt{\sum_{u\in U}(R_{u,i}-\overline R_i)^2}\sqrt{\sum_{u\in U}(R_{u,j}-\overline R_j)^2}}Similarity between two items i and j is measured by computing the Pearson-r correlation. To make the correlation computation accurate, first isolate the co-rated cases(i.e., cases where the users rated both i and j). Let the set of users who both rated i and j are denoted by U. Take the example again: \overline R_{HP}=\frac{13}{3}, overline R_{PC}=3.4. The set of users who both rated Harry Potter and The Avengers is U={Carol,Dave,Eve}. Then the similarity is \frac{(4-4.33)(3-3.4)+(4-4.33)(4-3.4)+(5-4.33)(4-3.4)}{\sqrt {(4-4.33)^2+(4-4.33)^2+(5-4.33)^2}\sqrt {(3-3.4)^2+(4-3.4)^2+(4-3.4)^2}}=0.435123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Implementation of Correlation-based Similarity * reference: Wang Menghan's implementation * * @author Hael Chan * @version 1.0 * @time 2017-11-05 23:51:09 */public double[][] calSimilarity(double [][]uiRating) &#123; /* uiRating is a u*i matrix, * where u is the number of users, * and i is the number of items */ int userNum = uiRating.length; // the number of rows of uiRating int itemNum = uiRating[0].length; // the number of columns of uiRating double[][] simResult = new double[itemNum][itemNum]; // a new matrix for similarity among items double[] average = new double[itemNum]; int[] nonZero = new int[itemNum]; for (int c = 0; c &lt; itemNum; c++) &#123; // for every item, iterate every user's rating, for (int r = 0; r &lt; userNum; r++) &#123; // so the nested for loop may be a bit nonintuitive if (uiRating[r][c] &gt; 0) &#123; // if uiRating[r][c] == 0, then just ignore it average[c] += uiRating[r][c]; nonZero[c]++; &#125; &#125; &#125; // Calculate every item's average rating for (int i = 0; i &lt; itemNum; i++) &#123; average[i] /= nonZero[i]; &#125; // Calculate the similarity for (int i = 0; i &lt; itemNum; i++) &#123; for (int j = i + 1; j &lt; itemNum; j++) &#123; // here j starts with i + 1 to improve efficient and avoid (i == j) case double num = 0, den = 0; double den1 = 0, den2 = 0; for (int k = 0; k &lt; userNum; k++) &#123; double diff1 = 0, diff2 = 0; if (uiRating[k][i] &gt; 0 &amp;&amp; uiRating[k][j] &gt; 0) &#123; diff1 = uiRating[k][i] - average[i]; // R_&#123;u,i&#125;-\overline R_i (in LaTex syntax) diff2 = uiRating[k][j] - average[j]; // R_&#123;u,j&#125;-\overline R_j (in LaTex syntax) num += diff1 * diff2; den1 += diff1 * diff1; den2 += diff2 * diff2; &#125; &#125; den = Math.sqrt(den1) * Math.sqrt(den2); simResult[i][j] = (den == 0) ? 0 : num / den; // remember the case that den may be zero simResult[j][i] = simResult[i][j]; &#125; &#125; return simResult; &#125; Adjusted Cosine Similaritysim(i,j)=\frac{\sum_{u\in U}(R_{u,i}-\overline R_u)(R_{u,j}-\overline R_u)}{\sqrt{\sum_{u\in U}(R_{u,i}-\overline R_u)^2}\sqrt{\sum_{u\in U}(R_{u,j}-\overline R_u)^2}}There’re tough users and easy users. Tough users tend to rate a relatively low score and maybe he has an average rate of 2.5, while easy users tend to have an average rate of 4.0. When computing the similarity, we have to consider the difference between users, and this is what adjusted cosine similarity does. Subtracting each valid rating by the user’s average rating to diminish the difference between users, and that would produce a more accurate result. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Implementation of Adjusted Cosine Similarity * * @author Hael Chan * @version 1.0 * @time 2017-11-07 09:49:51 */ public double[][] calSimilarity(double [][]uiRating) &#123; /* * Basically the method is the same as the * implementation of Correlation-based Similarity, * except the computation of average is different. * The correlation-based calculates the average of * column vector, while the adjusted cosine computes * the average of row vector. */ int userNum = uiRating.length; int itemNum = uiRating[0].length; double[][] similarityResult = new double[itemNum][itemNum]; double[] average = new double[userNum]; int[] nonZero = new int[userNum]; for (int r = 0; r &lt; userNum; r++) &#123; for (int c = 0; c &lt; itemNum; c++) &#123; if (uiRating[r][c] &gt; 0) &#123; average[r] += uiRating[r][c]; nonZero[r]++; &#125; &#125; &#125; // Calculate every user's average rating instead of every item's for (int i = 0; i &lt; userNum; i++) &#123; average[i] /= nonZero[i]; &#125; for (int i = 0; i &lt; itemNum; i++) &#123; for (int j = i + 1; j &lt; itemNum; j++) &#123; double num = 0, den = 0; double den1 = 0, den2 = 0; for (int k = 0; k &lt; userNum; k++) &#123; double diff1 = 0, diff2 = 0; // only calculate those co-rated items, // which means the user k both rated i and j if (uiRating[k][i] &gt; 0 &amp;&amp; uiRating[k][j] &gt; 0) &#123; diff1 = uiRating[k][i] - average[k]; // subtract user's average rating diff2 = uiRating[k][j] - average[k]; num += diff1 * diff2; den1 += diff1 * diff1; den2 += diff2 * diff2; &#125; &#125; den = Math.sqrt(den1) * Math.sqrt(den2); similarityResult[i][j] = (den == 0) ? 0 : num / den; similarityResult[j][i] = similarityResult[i][j]; &#125; &#125; return similarityResult; &#125; Prediction ComputationWeighted SumThis method computes the prediction on an item i for a user u by computing the sum of the ratings given by the user on the items similar to i. Each ratings is weighted by the corresponding similarity s_{i,j} between items i and j. P_{u,i}=\frac{\sum_{all\ similar\ items,N}(s_{i,N}*R_{u,N})}{\sum_{all\ similar\ items,N}(|s_i,N|)}For this to work best, R_u,N should be a value in the range -1 to 1. Our ratings are in the range 1 to 5. So we will need to convert our ratings to the -1 and 1 scale. Here’s two formulas:(reference from IT-533 Item-Based Recommender Systems (with Cosine Similarity and Python Code))Normalization NR_{u,N}=\frac{2(R_{u,N}-Min_R)-(Max_R-Min_R)}{Max_R-Min_R}Denormalization R_{u,N}=\frac{1}{2}((NR_{u,N}+1)\times (Max_R-Min_R))+Min_RExample of predicting Alice’s rating on Harry Potter:If we use the prediction formula directly: P_{Alice,HP}=\frac{0.526\times 3+1\times 5+0.321\times 4-0.955\times1}{0.526+1+0.321+0.955}=2.46This is not an accurate prediction. Since it’s intuitive that Harry Potter is similar to Titanic(Dave rated 4 both and Eve rated 5 both), so Alice’s rate on Harry Potter should be similar to her rate on Titanic. So let’s have a look on normalization result:Normalize Alice’s rating: a=(\_,0,1,0.5,-1). Using these normalized ratings, prediction would be: P_{N(Alice,HP)}=\frac{0.526\times 0+1\times 1+0.321\times 0.5+(-0.955)\times(-1)}{0.526+1+0.321+0.955}=0.755This is Alice normalized rating on Harry Potter. And to denormalize it: R_{Alice,HP}=\frac{1}{2}((P_{N(Alice,HP)}+1)\times (Max_R-Min_R))+Min_R=\frac{1}{2}((0.755+1)\times 4)+1=4.51And it’s an more accurate prediction. 1234567891011121314151617181920212223242526272829/** * originalPrediction * @author Hael Chan * @version 1.0 * @time 2017-11-08 13:30:23 */public double originalPrediction(int userID, int itemID)&#123; // compute the prediction on an item i for a user u // by computing the sum of the ratings given by the user // on the items similar to i double den = 0.0, num = 0.0; for (int i = 0; i &lt; uiRating[0].length; i++)&#123; // go through every item // Here all items, except for the object item itself, // is calculated in the weighted sum(for convenience). // For better performance, only those similar items should be considered. if (i != itemID &amp;&amp; uiRating[userID][i] &gt; 0)&#123; den += Math.abs(similarityResult[i][itemID]); num += similarityResult[i][itemID] * uiRating[userID][i]; &#125; &#125; double predictScore = 0.0; if (den != 0) &#123; predictScore = num / den; &#125; return predictScore;&#125; 123456789101112131415161718192021222324252627282930313233343536373839/** * normalizedPrediction * @author Hael Chan * @version 1.0 * @time 2017-11-18 13:28:57 */public double normalizedPrediction(int userID, int itemID) &#123; // using normalization and denormalization to // make a more accurate prediction int itemNum = uiRating[0].length; double[] normalizedRate = new double[itemNum]; // maxR and minR are constants which are predefined // final static int maxR = 5; // final static int minR = 1; // create a vector, storing user's normalized rating for (int i = 0; i &lt; itemNum; i++) &#123; if (uiRating[userID][i] != 0) &#123; normalization[i] = (2 * (uiRating[userID][i] - minR) - (maxR - minR)) / (maxR - minR); &#125; &#125; double den = 0.0, num = 0.0, normalizedScore = 0.0, denormalizedScore = 0.0; for (int i = 0; i &lt; itemNum; i++) &#123; if (i != itemID &amp;&amp; uiRating[userID][i] != 0) &#123; den += Math.abs(similarityResult[i][itemID]); num += similarityResult[i][itemID] * normalization[i]; &#125; &#125; if (den &gt; 0) &#123; normalizedScore = num / den; denormalizedScore = 0.5 * ((normalizedScore + 1) * (maxR - minR)) + minR; &#125; return denormalizedScore;&#125; RegressionIn practice, the similarities computed using cosine or correlation measures may be misleading in the sense that two rating vectors may be distant(in Euclidean sense) yet may have very high similarity. The basic idea is to use the same formula as the weighted sum technique, but instead of using the similar item N’s “raw” ratings values R_{u,N}‘s, this model uses their approximated values R_{u,N}' based on a linear regression model. \overline{R_N'}=\alpha\overline R_i+\beta+\epsilonThe respective vectors of the target item i and the similar item N are denoted by R_i and R_N. About linear regression, maybe it’s a good choice to refer to the machine learning article, in which I briefly introduced linear regression. Experimental Evaluationx: determines what percentage of data is used as training and test sets.ML: the data set with 943 rows and 1682 columns.sparsity level: 1-\frac{nonzero\ entries}{total\ entries}MAE: mean absolute error. MAE=\frac{\sum_{i=1}^n|p_i-q_i|}{N}Reference: Item-based Collaborative Filtering Recommendation Algorithms IT-533 Item-Based Recommender Systems (with Cosine Similarity and Python Code) 100K Dataset|GroupLens]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>recommender system</tag>
        <tag>reading report</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning Note]]></title>
    <url>%2F2017%2F11%2F01%2Fmachine-learning-note%2F</url>
    <content type="text"><![CDATA[Week OneIntroductionWhat is machine learning? Field of study that gives computers the ability to learn without being explicitly programmed. — By Arthur Samuel A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T as measured by P improves with experience E. — By Tom Mitchell Machine learning algorithmsSupervised learning Regressiontry to map input variables to some continuous function. Classificationpredict results in a discrete output. Unsupervised learningapproach problems with little or no idea what our results should look like Example: Clustering Non-clustering Linear Regression with One VariableSome notations:m: Number of training examplesx: “input” variable / featuresy: “output” variable / “target” variable(x^{(i)},y^{(i)}) : ith training example: Note that the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation. Hypothesis Function and Cost FunctionA slightly more formal description of supervised learning problem is that given a training set, to learn a function h : X → Y so that h(x) is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. In this example of linear regression with one variable, the hypothesis function can be denoted as h_\theta(x)=\theta_0+\theta_1x(maybe we Chinese students are more familiar with the form like h(x)=kx+b) Here \theta_0 and \theta_1 are just parameters. And our goal is to choose \theta_0 and \theta_1 so that h_\theta(x) is close to y for our training examples(x,y).The cost function takes an average difference of all the results of the hypothesis with inputs from x’s and the actual output y’s. J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=1}^m(\hat{y}_i-y_i)^2=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x_i)-y_i)^2This function is otherwise called the “Squared error function”, or “Mean squared error”. The coefficient 1/2 is used for gradient descent so that the partial derivative result will be cleaner. Gradient Descentthe Gradient descent algorithm: repeat until convergence { \theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\ \ (simultaneously\ update\ \theta_0\ and\ \theta_1)} The value of α should not be too small or too large.If α is too small, gradient descent can be slow.If α is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.In general, gradient descent can converge to a local minimum, even with the learning rate α fixed. After calculating partial derivation, we can get the algorithm as : repeat until convergence { \theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})\cdot x^{(i)} (update θ0 and θ1 simultaneously)} Linear Algebra ReviewMatrix: 2-dimensional array.Vector: An n×1 matrix Notation:Generally the uppercase letters are used for matrix and the lowercase letters are used for vector. Matrix ManipulationAddition \begin{bmatrix} a&b\\c&d \end{bmatrix}+\begin{bmatrix} w&x\\y&z \end{bmatrix}=\begin{bmatrix} a+w&b+x\\c+y&d +z\end{bmatrix}\\Scalar multiplication \begin{bmatrix} a&b\\c&d \end{bmatrix}\times x=\begin{bmatrix} a\times x&b\times x\\c\times x&d\times x \end{bmatrix}Matrix-vector multiplication \begin{bmatrix} a&b\\c&d\\e&f \end{bmatrix}\times\begin{bmatrix} x\\y \end{bmatrix}=\begin{bmatrix}ax+by\\cx+dy\\ex+fy \end{bmatrix}Let A be an m×n matrix, x be an n-dimensional vector, then the result A×x will be an m-dimensional vector.To get yi, multiply A’s ith row with elements of vector x, and add them up. Matrix-matrix multiplication \begin{bmatrix} a&b\\c&d\\e&f \end{bmatrix}\times\begin{bmatrix} w&x\\y&z \end{bmatrix}=\begin{bmatrix} aw+by&ax+bz\\cw+dy&cx+dz\\ew+fy&ex+dy \end{bmatrix}Let A be an m×n matrix, B be an n×o matrix, then the result A×B will be an m×o matrix.The ith column of the matrix C is obtained by multiplying A with the ith column of B.(for i=1,2,…,o). Then the calculation can be simplified to matrix-vector multiplication. Matrix multiplication propertiesNot commutativeLet A and B be matrices. Then in general, A×B≠B×A. AssociativeA×(B×C)=(A×B)×C Special matrixIdentity MatrixThe identity matrix, which is denoted as I(sometimes with n×n subscript), simply has 1’s on the diagonal (upper left to lower right diagonal) and 0’s elsewhere. For example: \begin{bmatrix}1&0&0\\0&1&0\\0&0&1\end{bmatrix}For any matrix A, A×I=I×A=A Matrix InverseIf A is an m×m matrix, and if it has an inverse(not all matrix have an inverse), A\times A^{-1}=A^{-1}\times A=IMatrices that don’t have an inverse are singular or degenerate. Matrix TransposeLet A be an m×n matrix, and let B=A^T. Then B is an n×m matrix, and B_{ij}=A_{ji}Week TwoMultivariate Linear Regressionfrom one variable to multiple variablesIn the first week’s course, we learned linear with one variable x, and the hypothesis could be h_{\theta}(x)=\theta_0+\theta_1x. As a matter of fact, there can be more than one variables. So here’re the new notations:m: the number of training examplesn: the number of features -x^{(i)} : input (features) of ith training example-x_j^{(i)} : value of feature j in ith training example The hypothesis should be transformed to: h_{\theta}(x)=\theta_0x_0+\theta_1x_1+...+\theta_nx_n=\sum_{i=0}^n\theta_nx_n(for convenience of notation, we define x0=1).Using the definition of matrix multiplication, our multivariable hypothesis function can be concisely represented as: h_{\theta}(x)=\begin{bmatrix}\theta_0&\theta_1&...&\theta_n\end{bmatrix}\begin{bmatrix}x_0\\x_1\\...\\x_n\end{bmatrix}=\theta^TxWe can see that linear regression with one variable is just the special case when n=1. Similarly, the new gradient descent algorithm would be represented as:repeat until convergence{ \theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)}-y^{(i)})x_j^{(i)}\ \ (simultaneously\ update\ \theta_j\ for\ j=0,...,n)} Feature ScalingThe idea is to make sure features are on a similar scale so that the gradient descent can be sped up.Generally, get every feature into approximately a -1]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
        <tag>learning note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[REM Reading Report]]></title>
    <url>%2F2017%2F10%2F31%2FREM-reading-report%2F</url>
    <content type="text"><![CDATA[REM Reading Report &amp; Future PlanOverviewREM &amp; PoUWREM(Resource-Efficient Mining) is a new blockchain mining framework that uses trusted hardware(Intel SGX) to achieve a fraction of the waste of PoW. It’s partially decentralized, and it achieves security guarantees similar to PoW. Its key idea, Proof-of-Useful-Work(PoUW), involves miners providing trustworthy reporting on CPU cycles they devote to inherently useful workloads. In a PoUW system, users can utilize their CPUs for any desired workload, and can simultaneously contribute their work towards securing a blockchain. Fundamental impediment of PoWAs Satoshi Nakamoto put Proof-of-Work(PoW) in BitCoin, PoW is widely used in blockchain so that the consensus can prevent an attacker from gaining majority power by cheaply masquerading as multiple machines. However, PoW in blockchains are wasteful, and it even has another name: Proof of Waste. PoWs serve no useful purpose beyond consensus and incur huge monetary and environmental costs, which is against FinTech’s demand. PoETMany attempts have been made to create a more resource useful consensus. However they have serious limitations.Intel recently introduced a new instruction set architecture extension in Intel CPUs called Software Guard Extension(SGX). SGX permits the execution of trustworthy code in an isolated, tamper free environment, and can prove remotely that outputs represent the result of such execution. And Intel proposed another innovative consensus: Proof of Elapsed Time(PoET). However, PoET presents two notable technical challenges: broken chip problem(an attacker that can corrupt a single SGX-enabled node can win every consensus round and break the system completely) and stale chip problem(miners tend to power mining rigs with cheap, outmoded SGX-enabled CPUs used solely for mining). REM addresses both the stale and broken chip problems. SGXSGX enables process execution in a Trusted Execution Environment(TEE), and specifically in SGX in a protected address space known as an enclave. An enclave protects the confidentiality and the integrity of the process from certain forms of hardware attack and other processes on the same host, including privileged processes like operating systems. SGX signs quotes in attestations using a group signature scheme called Enhanced Privacy ID or EPID, and Intel made the design choice that attestations can only be verified by accessing Intel’s Attestation Service(IAS), a public Web service maintained by Intel whose primary responsibility is to verify attestations upon request. PoUW and REMtwo key assumptionsThe basic idea of PoUW, and thus REM, is to replace the wasteful computation of PoW with arbitrary useful computation. Since it is only partially decentralized, it relies for security on two key assumptions about the hardware manufacturer’s behavior: First, Intel correctly manages identities, specifically that it assigns a signing key(used for attestations) only to a valid CPU. Second, Intel does not blacklist valid nodes in the network, rendering their attestations invalid when the IAS is queried.If Intel didn’t follow the two assumptions and was detected in any context, the company’s reputation and the perceived utility of SGX would be undermined and Intel would gain little revenue. So generally we can trust Intel SGX. the architecture of REMThere are three types of entities in the ecosystem of REM: a blockchain agent, one or more REM miners, and one or more useful work clients.The useful work clients supply useful workloads to REM miners in the form of PoUW tasks, each of which encompass a PoUW enclave and some input.The blockchain agent collects transactions and generates a block template, a block lacking the proof of useful work(PoUW). A REM miner will attach the required PoUW and return it to the agent. The agent then publishes the full block to the P2P network, making it part of the blockchain and receiving the corresponding reward. Although CPU cycles would have been a more accurate metric, they are vulnerable to manipulation. The operating system may set their values arbitrarily and even have them double-count cycles. Therefore, REM chose instruction counting for securely evaluating effort with the existing tools available in SGX.The workflow of the PoUW toolchain is as shown below: First, the useful work code (usefulwork.cpp), C / C++ source code, is assembled while reserving a register as the instruction counter. Next, the assembly code is rewritten by the toolchain such that the counter is incremented at the beginning of each basic block (a linear code sequence with no branches) by the number of instructions in that basic block. The count is performed at the beginning of a block rather than its end to prevent a cheater from jumping to the middle of a block and gaining an excessive count. PoUW attestations is formed with two-layer hierarchical attestations. Zhang et al hard-code only a single program’s fingerprint into the blockchain, a static-analysis tool called compliance checker. The compliance checker runs in a trusted environment and takes a user-supplied program as input.Every PoUW then includes two parts: The useful work program attestation on the mining success, and an attestation from the compliance checker of the program’s compliance. Note that the compliance attestation and the program’s attestation must be signed by the same CPU. Otherwise an attacker that compromises a single CPU could create fake compliance attestations for invalid tasks. REM读书报告中文版概述REM与PoUWREM（资源节约型挖矿）为一种新型的使用可信任硬件（Intel SGX）的区块链挖矿框架，大幅度减少了工作量证明(PoW)的浪费。部分去中心化的REM实现了与PoW类似的安全性保证。其核心思想，有效工作量证明(PoUW)，使得矿工提供所贡献的有效工作负载的CPU周期的可信任证明。在PoUW系统中，用户可以将CPU用于任何期望工作负载，同时贡献其工作来使得区块链更安全。 工作量证明的重大缺陷中本聪在比特币中使用的工作量证明PoW，被广泛应用于区块链技术，该共识机制可以有效防止恶意攻击者通过低成本地伪装成多台机器以获得大多数权力。然而，区块链的工作量证明是浪费的，它甚至还有一个别名：浪费量证明。除了实现共识，它别无它用，却造成了大量的资金与环境浪费，而这与金融科技的愿景是相违背的。 PoET为了实现更加节约型的共识机制，已经有许多共识机制进行尝试。不过往往这些共识机制都有非常严格的限制。近日Intel在其CPU中推行了一种新型指令集扩展结构，称为SGX(Software Guard Extension)。SGX允许可信任代码在隔绝、防干扰的环境中执行，并且远程验证程序执行的输出结果。在SGX的基础上，Intel提出了新的共识机制：运行时间证明(Proof of Elapsed Time, PoET)。然而，PoET有两个显著的技术挑战：芯片沦陷问题和芯片老旧问题。 SGXSGX使进程执行在可信任执行环境(Trusted Execution Environment, TEE)中，而且SGX中专门有一块受保护的名为enclave（暂译为保护领地）的地址。Enclave保证了进程的机密性和完整性，避免来自硬件的攻击以及其他优先进程如操作系统等影响。SGX在认证过程中使用一种名为强化隐私ID(Enhanced Privacy ID, EPID)的群签名方案。同时Intel决定认证只能通过Intel认证服务(Intel’s Attestation Service)进行，IAS是Intel维持的公共网络服务，其首要责任是验证请求的认证。 PoUW和REM两个关键假设PoUW及REM的基本思想是将PoW中浪费的计算量替代为任意有效计算量。因为它是部分去中心化的，所以其安全性依赖关于硬件制造商行为的两个关键假设：第一，Intel正确地进行身份管理，特别是对一个有效CPU只分配唯一的签名密钥（用于认证）。第二，Intel不会针对网络中的节点设立黑名单，不会当IAS请求响应时假装其认证无效。如果Intel违背上述两条假设中的任意一条，只要被检测出来，其公司的声誉以及用户对SGX的认同会大大削减，Intel得不偿失。所以总体而言我们可以信任Intel SGX。 REM框架在REM的生态中有三类实体：一位区块链代理，一位或多位REM矿工，以及一位或多位有效工作客户。有效工作客户将有效工作负载以PoUW任务的形式提供给REM矿工，每一个任务包含一个PoUW enclave以及一些输入。区块链代理收集处理，生成一个区块模板，一个没有PoUW的区块。REM矿工会附上所需的PoUW的区块并返回该区块。区块链代理随后将完整的区块发布至P2P网络，使其成为区块链的一部分，而矿工也获得对应的奖励。 尽管CPU周期也许是更准确的测量标准，它却易被操控。操作系统可以任意修改其值，甚至可以翻倍。因此，在已有SGX工具的情况下，REM选择对指令计数，以保证评价的安全性。PoUW工具链的流程如下：首先，有效工作代码，C或C++源码，以汇编形式处理，同时预留一个寄存器作为指令计数器。然后，工具链将汇编代码进行重写，使得计数器在每个基块（无分支的线性代码序列）时根据基块的指令数目进行计数。同时为了保证正确性，工具链还实现了两个强制措施：强制代码不可写入，以及强制单线程操作。 PoUW的认证过程是两级认证。Zhang Fan等人硬编码单个程序的“指纹”(fingerprint)——一种称为一致性检查的静态分析工具——至区块链中。一致性检查在可信任环境中运行，以用户提供的程序作为输入。每一份PoUW包含两部分：成功挖矿时的有效工作程序认证，以及来自一致性检查的程序一致性认证。注意到一致性认证以及程序认证的签名必须来自同一CPU。否则攻击者可以攻击单个CPU后为无效任务伪造一致性认证。 Personal perspective虽然在5.1的Why Count Instructions中解释了为什么采用指令计数的方式。 While instructions are reasonable estimates of the CPU effort, CPU cycles would have been a more accurate metric. However, although cycles are counted, and the counts can be accessed through the CPU’s performance counters, they are vulnerable to manipulation. The operating system may set their values arbitrarily, allowing a rational operator, who controls her own OS, to improve her chances of finding a block by faking a high cycle count. Moreover, counters are incremented even if an enclave is swapped out, allowing an OS scheduler to run multiple SGX instances and having them double-count cycles. Therefore, while instruction counting is not perfect, we find it is the best method for securely evaluating effort with the existing tools available in SGX. 不过个人认为还是可以采用执行时间证明(Proof of Execution Time, PoET’)的方法实现共识。CPU的晶振周期与时钟周期是固定的（本来我以为单个机器的机器周期是固定不变的，但是机器周期即为CPU周期，所以才知道是可以由操作系统改变的）。可以使用执行时间÷时钟周期（晶振周期）÷某一常数近似估计指令数目，而不需要专门设计工具链对汇编语言进行计数。另外，一篇名为Malware Guard Extension: Using SGX to Conceal Cache Attacks(Extend Version)的论文也值得引起我们对SGX安全性的重视。（这篇论文是我近日查找资料时不经意看到的搜狐报道的英特尔 SGX：是用来隐藏恶意软件，而不是保护系统；会泄漏加密密钥后去找的论文，还没有仔细看）]]></content>
      <tags>
        <tag>reading report</tag>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链的共识机制]]></title>
    <url>%2F2017%2F10%2F24%2Fabout-blockchain-consensus%2F</url>
    <content type="text"><![CDATA[区块链的共识机制 Blockchain Consensus区块链如何在分布式场景下达成一致，关键便是共识机制。共识协议的稳定性和防攻击性保证了区块链的安全运行。现整理常见的共识机制，包括PoW工作量证明(Proof of Work)、PoET运行时间证明(Proof of Elapsed Time)、PBFT拜占庭容错算法(Practical Byzantine Fault Tolerance)，以及两种新型的共识机制：PoL幸运值证明(Proof of Luck)以及PoUW有效工作证明(Proof of Useful Work)。 工作量证明 Proof of Work工作量证明是矿工在处理交易数据（对数据也是进行哈希）的同时不断的进行哈希计算，求得一位前23位为0的哈希值，这个值成为nonce黄金数。当全网有一位矿工哈希出nonce时，他就会把自己打包的区块公布出去，其他节点收到区块验证区块后就会一致性认为这个区块接到了区块链上，就继续进行下一个区块的打包和哈希计算。在这个过程中，中本聪通过算力的比拼牺牲了一部分最终一致性（因为会有分叉的产生）并且需要等待多个确认，但是这种简单暴力的方法却保证了整个区块链系统的合法性，而且把区块链系统的健壮性提升到极致，就算全网只剩下一个节点运行，这个区块链系统还是会继续运行下去。最后POW也充分提高了区块链系统的安全性，依靠51%攻击理论去破坏区块链系统是只有政府或者疯子才会采取的方法。 优点： 完全去中心化 节点自由进出，容易实现。 破坏系统花费的成本巨大 缺点： 对节点的性能网络环境要求高 无法达成最终一致性 浪费能源 详情可参见 Bitcoin: A Peer-to-Peer Electronic Cash System 消耗时间证明 Proof of Elapsed Time为了提高分布式共识的效率，一个优良的彩票函数(lottery function)有以下几个特征： 公平：该函数应在最广泛的可能参与者中进行领导选举的分布 投入：控制领导选举进程的花费，应当与从中的收益成正比 验证：对于所有的参与者而言，验证领导为合法选举产生的步骤应相对简单 消耗时间证明算法使用新型安全的CPU指令来实现上述目标。通过这些特点，PoET保证了领导选举过程的安全性和随机性，而不需要像大多数证明算法一样需要消耗大量资源。 详情可参见Introduction - Sawtooth latest documentation(Proof of Elapsed Time) 拜占庭容错算法 Practical Byzantine Fault Tolerance这是一种基于消息传递的一致性算法，算法经过三个阶段达成一致性，这些阶段可能因为失败而重复进行。假设节点总数为3f+1，f为拜占庭错误节点： 当节点发现leader作恶时，通过算法选举其他的replica为leader。leader通过pre-prepare （第一个协议阶段）消息把它选择的 value广播给其他replica节点，其他的replica节点如果接受则发送 prepare（第二个协议阶段），如果失败则不发送。一旦2f个节点接受prepare消息，则节点发送commit（第三个协议阶段）消息。当2f+1个节点接受commit消息后，代表该value值被确定 如下图表示了4个节点，0为leader，同时节点3为fault节点，该节点不响应和发出任何消息。最终节点状态达到commited时，表示该轮共识成功达成。 注：预准备阶段（pre-prepare）： 主节点分配一个序列号n给收到的请求，然后向所有备份节点群发预准备消息，预准备消息的格式为&lt;&lt;PRE-PREPARE,v,n,d&gt;,m&gt;，这里v是视图编号，m是客户端发送的请求消息，d是请求消息m的摘要。 准备阶段（prepare）： 如果备份节点i接受了预准备消息&lt;,m&gt;，则进入准备阶段。在准备阶段的同时，该节点向所有副本节点发送准备消息&lt;PREPARE,v,n,d,i&gt;，并且将预准备消息和准备消息写入自己的消息日志。如果看预准备消息不顺眼，就什么都不做。 确认阶段（commit）： 当(m,v,n,i)条件为真的时候，副本i将&lt;COMMIT,v,n,D(m),i&gt;向其他副本节点广播，于是就进入了确认阶段。优点：上述其他算法都脱离不了币的存在，币的存在及它的奖励机制会让区块链这一单一的世界穷者更穷，富者更富。共识效率高，可实现高频交易。缺点：当系统只剩下33%的节点运行时，系统会停止运行。 幸运值证明 Proof of Luck来自UC Berkley 的 Mitar Milutinovic等学者为了克服PoW的资源消耗、交易效率低等问题，在可信任执行环境(Trusted Execution Environments)中提出了一种新型共识算法：幸运值证明。在攻击者理性以及大多数参与者良性的情况下，使用最少量的资源与算力以实现交易验证的低延时。幸运值证明由两个函数组成：PolRound（幸运值证明循环）以及PolMine（幸运值证明挖矿）。在每次循环的开始，参与者准备通过调用PoLRound函数，传递已知的最新区块。经过一段时间（ROUND_TIME）后，参与者调用PoLMine函数挖掘新的区块。PolMine函数会生成[0,1)区间内一个满足均匀分布的随机值，根据该随机值决定这一轮所有的区块中的胜出区块。与PoET类似，Proof of Luck也是一种彩票函数，保证了随机性与安全性。 有效工作量证明 Proof of Useful Work面对工作量证明造成的大量浪费，Cornell的Fan Zhang等学者希望可以更充分地利用CPU资源，因此在改进PoET算法的基础上提出了有效工作量证明算法，并根据有效工作量证明设计了名为REM（资源节约型挖矿）的系统。REM系统中有三类实体：区块链代理，一个或多个REM矿工，以及一个或多个有效工作客户。有效工作客户将需要计算的工作以PoUW任务的形式提供给REM矿工，矿工接受区块模板及PoUW工作后便执行有效工作指令，可以执行科学实验、药学研究等。与PoW的完全去中心化不同的是，PoUW实现的是部分中心化(partially decentralized)。它依赖于Intel的SGX(Software Guard Extension)平台。SGX允许在隔离、免受干扰的环境中执行可信任代码，并且通过远程证明输出代表着执行结果。当然，这一切是基于SGX可信的基础。 Reference: 区块链共识机制浅谈 Bitcoin: A Peer-to-Peer Electronic Cash System Introduction - Sawtooth latest documentation Proof of Luck: an Efficient Blockchain Consensus Protocol REM: Resource-Efficient Mining for Blockchains]]></content>
      <tags>
        <tag>区块链</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21岁 你好]]></title>
    <url>%2F2017%2F10%2F23%2F21-year-birthday-reflection%2F</url>
    <content type="text"><![CDATA[霜降。又到了这个平凡而又特殊的日子，转眼已经21岁了呐。不会矫情地慨叹“要奔三”等话语，只是轻道一句，时光太匆匆。从紫金港到玉泉，从freshman到sophomore再到junior，从懵懂无知到懵懂依旧。只是像一只蜗牛罢，一步一步倔强地往上爬。这个学期算是加入了计院的系统安全与虚拟化的实验室，和同级的佼佼者、研究生、老师同处一室，感受到自己的渺小，不过也作出了自己的小小贡献，亦愈发迫切地渴望提高。区块链Blockchain，似曾相识而又陌生的分布式技术，在阅读了一篇篇论文后，方有了一定的了解。而接下来要构思的专利及论文，依然路漫漫。进入大学后第一次获得了奖学金。虽然是凭借在团学联的学生工作获得的社会工作奖学金，而不是证明成绩的学业奖学金，不过知足啦。大三学年，争取在学业与创新方面都有所进步。已经浪了两年，望不再辜负自己。QQ上的生日提示肆意传播，从一大早起便收到了来自认识的不认识的好友的生日祝福。相似的祝福语，虽然只是系统自动发送的祝福语，为沉寂的手机带来一丝振动，不会一个一个去回复，可能会带来双方的尴尬，不过还是谢谢啦。以及那些记得我生日的好孩子们，感谢认识你们，比心。❤21岁，新的十年之始。愿不忘初心，砥砺前行。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统下常用指令]]></title>
    <url>%2F2017%2F10%2F21%2FlinuxCommands%2F</url>
    <content type="text"><![CDATA[Foreword现整理一下Linux系统下常用的指令，如无特殊说明，这些指令也都可以在macOS系统上执行。所有指令均在Ubuntu 16.04.3 LTS版本下运行通过。参考Stanford大学的Chris Gregg在YouTube上的教程 Linux文件系统简介Linux的文件系统可以用数据结构中的树表示。使用tree指令便可以以树状结构列出目录内容（不过macOS下不能直接使用tree指令），比较直观清晰。 工作路径在Terminal下可以输入指令 pwd (print working directory)显示当前的工作路径（绝对路径）。工作路径有两种：绝对路径与相对路径。绝对路径就是从根目录(root directory)/开始的路径，相对路径是从主目录(home directory)~开始的路径。一般情况下我们都可以使用相对路径来表示我们的工作路径。另外，.表示当前路径，..表示上一级路径。 cdcd: change directorycd 路径名： 定位至目标目录cd 或cd ~： 定位至主目录cd - ： 返回至之前目录cd ..： 返回至父目录 catcat: concatenatecat 文件名： 输出文件内容。注意对文件夹无法进行cat命令。cat 文件名1 文件名2 ... 文件名n： 输出多个文件内容 lsls: listls： 列出所有非隐藏文件ls -1： 以单列的形式列出所有非隐藏文件。（即一行只显示一个文件/文件夹）ls -l： 列出所有非隐藏文件，包含更多信息：包括文件大小、是否为文件夹、ls -a： 列出所有文件，包括隐藏文件。（文件名以.开头的都是隐藏文件/隐藏文件夹）ls -rt： 按照时间修改顺序倒序显示文件ls -后面的指令可以配合使用，例如ls -alrt便是以倒序显示所有文件，并且包含更多详细信息。 pushd / popdpushd: push directorypopd: pop directory在Terminal中，经过几次cd改变路径后，有没有什么快速跳转至之前某一路径的快捷指令呢？答案就是使用pushd和popd指令，利用压栈和出栈的思想实现快速跳转。具体使用方法：pushd 新路径： 对当前路径进行压栈操作，然后跳转至新路径popd： 跳转至栈顶路径举例：假设当前我的路径为~/Documents，使用指令pushd ../Downloads后，栈中保存的路径为~/Documents，而我的路径跳转到了主目录下的Downloads文件夹。此时使用指令popd便可以跳转至栈顶路径，即~/Documents。 manman: manualman 指令名： 查看对应命令的指导手册例如：man ls，便可以查看完整的ls指令。进入指导手册后，还可以进行一些操作：可以通过上下方向键，或者J和K进行文本的浏览。使用/查找内容指令可以查找特定内容。 在查找时按下n（即键盘上的N键）可以查找下一处，按下N（即shift和N一起按）可以查找上一处。按下Q即退出指导手册。 man -k 关键词： 显示所有指导手册中带有关键词的指令。例如： man -k printf： 我们会发现，除了printf外，还有许多长得类似的指令。同时macOS与Ubuntu上显示的指令是不一样的。Linux only：在Ubuntu下有printf(1)和printf(3)两条名称相同的指令，其中printf(1)是UNIX的系统指令，而printf(3)即是我们熟悉的C语言中的输出指令。可以通过指令man 3 printf查看C语言的printf手册。所以我们在Linux下使用man也可以查看C语言的手册。 cp / mvcp: copymv: movecp 源文件 新路径： 复制源文件至新路径下，如果新路径原先不存在，则会自动生成对应路径（即文件夹）。cp -r 源文件夹 新路径： 复制文件夹至新路径下。-r 表示recursive即递归，表示将源文件夹下的所有文件都复制，即实现了整个文件夹的复制。注意新路径下如果存在与源文件同名的文件，则直接会被覆盖。 mv的用法与cp基本一样。不过对文件夹进行操作时无需使用-r命令。 rmrm: removerm 文件rm -r 文件夹注意rm操作会直接删除对应文件/文件夹，而不存在回收站之类的东西（虽然可以有backup，但是……我不会）。所以在执行rm操作时需谨慎。 grepgrep &quot;关键字&quot; 文件名： 列出文件中所有包含pattern的行 关键字中有两个特殊的字符，.和。.可以代表任一字符`表示*前面的字符可以连续出现任意次数（包括0次）。 例如：grep “dif*” demo.txt`中，会将包含di、dif、diff的所有行都列出来。 配合正则表达式，grep可以实现高效的查找。这里仅举几个例子供参考：grep &quot;[ab]e&quot; fileName： 查找所有包含ae或者be的行grep &quot;^A&quot; fileName： 列出所有以A开头的行grep &quot;^B&quot; fileName： 列出所有以B结尾的行具体的可以使用man grep指令查看手册或者网上搜寻正则表达式的相关教程。 findfind . -name 文件名： 在当前路径下（包括当前路径的子路径）寻找对应文件与grep命令稍有不同，在find命令下使用*可以表示任意字符。find . -type d： 在当前路径下寻找所有文件夹 ctrl+C中断当前正在执行的指令]]></content>
      <tags>
        <tag>linux</tag>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS常用快捷键整理]]></title>
    <url>%2F2017%2F10%2F20%2FmacOS-shortcuts%2F</url>
    <content type="text"><![CDATA[Foreword一些功能及其对应的符号：⌘：command 其功能与Windows系统下的Ctrl类似，例如command+C对应Windows下的Ctrl+C等。⌥：option 一般情况下需与其他功能键配合使用；在输入文字时option+字母可以快捷输入各种符号。⌃：control 注意不要与Windows的Ctrl混淆。⇧：shift 通常配合command一起使用。⇪：caps lock 用于切换大小写、中英文输入法，符号与shift相似，不过在后面的快捷键中不会用到该键位。 系统常用快捷键下面列举的快捷键在macOS系统下的大部分软件内都可以操作，非常实用。一些快捷键如果有记忆方式我会在括号中标注~⌘ C：复制⌘ V：粘贴⌘ X：剪切注意在Finder中无法使用⌘ X对文件进行剪切操作。如果需要对文件进行剪切操作，则应对文件使用⌘ C后，在需要粘贴的地方使用快捷键⌥ ⌘ V即可实现剪切与粘贴的操作。⌘ Z：撤销 ⌘ A(command all)：全选⌘ S(command save)：保存⌘ F(command find)：查找查找一般是查找某些文字。在Finder中进行查找时，会找出所有包含对应关键字的文件。 ⌘ H(command hide)：隐藏当前应用的所有窗口⌘ M(command minimize)：最小化当前窗口关于隐藏和最小化，看上去差不多不过还是有一些不同的。比如打开了多个Word文档，⌘ H会把所有的Word文档都隐藏，而⌘ M只会将最前面的一个Word最小化。另外，被隐藏的应用可以通过⌘ tab进行切换，而被最小化的应用无法直接通过⌘ tab进行切换（下文会提到）。 ⌘ tab：切换应用按下⌘ tab后，继续按住command键，可以看到所有当前正在运行的应用程序。然后按tab便可以在不同的应用之间切换。注意无法直接切换到被最小化的程序，需要用到下面这条比较复杂的快捷键。⌘ tab ⌥：切换至最小化的程序使用方法：按下⌘ tab，调出当前运行的程序后，一直按住⌘ command，按tab将光标定位到想要切换的程序，松开tab，按下⌥ option键，即可切换至最小化的应用程序。⌘ ~：同一程序不同窗口间切换有时可能会打开同一应用程序的多个窗口。还是以打开多个Word文档为例：需要在不同文档间切换时就可以使用该快捷键。~对应的就是数字键1左边、tab上面的那一颗按键。 ⌘ Q(command quit)：退出应用⌘ W(command window)：关闭当前窗口⌘ Q是将整个应用程序退出，同时不再占用任何进程资源；而⌘ W则只是将程序的一个窗口关闭。（可能有点难懂，还是以打开多个Word文档为例：⌘ Q是将所有窗口的关闭，同时Word本身的进程也退出了；而⌘ W则只是关闭其中的一个文档，其他文档不受印象。） ⌘ O(command open)：打开⌘ N(command new)：新建 ⌘ ,：偏好设置很多应用程序都会有偏好设置，可以在里面对该程序进行一些设置。⌘ space：切换输入法⌃ space：调用spotlight注意切换输入法不是Windows上的Ctrl+Shift，在macOS上是⌘ space（space即空格）。注意有可能部分机器上切换输入法和调用spotlight的快捷键正好相反。 ⇧ ⌘ 3：全屏幕截图⇧ ⌘ 4：选中区域截图macOS自带的截图快捷键，默认保存格式为PNG。 ⌃ ⌘ space：输入Emoji表情在需要输入Emoji的地方使用快捷键⌃ ⌘ space就可以输入各种Emoji表情啦~ 浏览器常用快捷键（以Safari为例）⌘ T(command tab)：新建标签页⌘ W(command window)：关闭标签页⇧ ⌘ ←：切换到前一个标签页⇧ ⌘ →：切换到后一个标签页⌘ 1~9：切换到第1~9个标签页上述快捷键不只是局限于浏览器，另外一些带有标签页的软件也都可以使用其中的部分或全部快捷键，例如PDF Expert等。 ⌘ R(command refresh)：刷新⌘ ←：后退⌘ →：前进在网页浏览时最常用到的几个快捷键 ⌘ L(command link)：编辑地址栏的地址⇧ ⌘ L：显示边栏⌘ D：添加书签⇧ ⌘ D：添加到阅读列表 文档处理常用快捷键（以Word为例）⌘ B(command bold)：加粗⌘ I(command italic)：斜体⌘ U(command underline)：下划线这三个快捷键在Word的工具栏中分别对应B*I*U三个选项。 ⌘ ←：光标定位至当前行的行首⌘ →：光标定位至当前行的行尾⌘ ↑：光标定位至当前段的段首⌘ ↓：光标定位至当前段的段尾⇧ ←：选中光标左边的单个字符⇧ →：选中光标右边的单个字符通过⌘和⇧ 的配合使用可以快速选择多个字符 ⌥ 1~9 A~Z：输入一些字符 CheatSheet介绍当然，macOS的快捷键远不止此，上述介绍的只是常用的快捷键。还有一些快捷键可以在Apple的官网查看。另外在此推荐一款快捷键软件：CheatSheet是一款查看快捷键的软件，可以访问其官网免费下载。在安装后只需要长按⌘ 便可查看当前软件的（几乎）全部快捷键。]]></content>
      <tags>
        <tag>tips</tag>
        <tag>macOS</tag>
        <tag>效率</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F10%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
